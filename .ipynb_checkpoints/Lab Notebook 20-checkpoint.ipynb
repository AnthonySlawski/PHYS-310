{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIb7AW-J_Q0j"
   },
   "source": [
    "# Lab Notebook 20\n",
    "\n",
    "In this notebook, we use a fully connected neural network to solve a previously seen problem in regression: the photometric redshift problem  We also explore the effect of loss function and learning rate schedule. \n",
    "\n",
    "*Modified from: Copyright: Viviana Acquaviva (2023). License: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "wCi2a2GB_Q0m"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential #the model is built adding layers one after the other\n",
    "from keras.layers import Dense #fully connected layers: every output talks to every input\n",
    "from keras.layers import Dropout #for regularization\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RELqQBID_Q0n"
   },
   "source": [
    "# Part 1: PhotoZ regression with a deep NN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLHnWtsJ_Q04"
   },
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6-Ir38f_Q05"
   },
   "source": [
    "Let us begin with the reduced (high-quality) data set we used for Bagging and Boosting methods. For reference, our best model achieved an outlier fraction of 4%.\n",
    "\n",
    "Read in 'sel_features.csv' and 'sel_target.csv' as X and y, respectively. You will need to shuffle X and y (use random_state=12) as we did in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "e8hFO3qM_Q05"
   },
   "outputs": [],
   "source": [
    "X=pd.read_csv('sel_features.csv', sep='\\t')\n",
    "y=pd.read_csv('sel_target.csv', sep='\\t')\n",
    "\n",
    "X, y = shuffle(X, y, random_state = 12)#seed to 12 for same 'random' results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the data into fifths; we would like to use a 60/20/20 split for training/validation/test. Define these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6307, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_apercor</th>\n",
       "      <th>g_apercor</th>\n",
       "      <th>r_apercor</th>\n",
       "      <th>i_apercor</th>\n",
       "      <th>z_apercor</th>\n",
       "      <th>y_apercor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>23.7774</td>\n",
       "      <td>23.4961</td>\n",
       "      <td>23.2445</td>\n",
       "      <td>22.9700</td>\n",
       "      <td>22.5860</td>\n",
       "      <td>22.4497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675</th>\n",
       "      <td>23.7430</td>\n",
       "      <td>23.3638</td>\n",
       "      <td>22.6674</td>\n",
       "      <td>21.7934</td>\n",
       "      <td>21.2195</td>\n",
       "      <td>21.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>24.1826</td>\n",
       "      <td>23.1667</td>\n",
       "      <td>22.6836</td>\n",
       "      <td>22.4811</td>\n",
       "      <td>22.3890</td>\n",
       "      <td>22.4926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>23.6480</td>\n",
       "      <td>23.2737</td>\n",
       "      <td>22.6016</td>\n",
       "      <td>22.3798</td>\n",
       "      <td>22.3236</td>\n",
       "      <td>22.3666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>24.0790</td>\n",
       "      <td>23.7875</td>\n",
       "      <td>23.3592</td>\n",
       "      <td>22.6754</td>\n",
       "      <td>22.4678</td>\n",
       "      <td>22.4220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      u_apercor  g_apercor  r_apercor  i_apercor  z_apercor  y_apercor\n",
       "4561    23.7774    23.4961    23.2445    22.9700    22.5860    22.4497\n",
       "3675    23.7430    23.3638    22.6674    21.7934    21.2195    21.0882\n",
       "3201    24.1826    23.1667    22.6836    22.4811    22.3890    22.4926\n",
       "780     23.6480    23.2737    22.6016    22.3798    22.3236    22.3666\n",
       "4205    24.0790    23.7875    23.3592    22.6754    22.4678    22.4220"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6307, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zhelio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>1.3944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675</th>\n",
       "      <td>0.9846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>0.1683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>0.4280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>0.8421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      zhelio\n",
       "4561  1.3944\n",
       "3675  0.9846\n",
       "3201  0.1683\n",
       "780   0.4280\n",
       "4205  0.8421"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: 60% for training, 40% for the combination of validation and testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=12)\n",
    "\n",
    "# Second split: Split the temporary set into 50% validation, 50% test (20% of the original dataset each)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aHqfJPv_Q05"
   },
   "source": [
    "We know that we need to scale our data! Do so below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1685403021297,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "lGcMKwtu_Q05",
    "outputId": "1bd10c4d-8302-408a-b51a-5e416d314aed"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1zYQ1yg_Q06"
   },
   "source": [
    "## Step 2\n",
    "\n",
    "In a regression problem, we will choose a different activation for the output layer (linear), and an appropriate loss function (MSE). Our input layer has **six neurons** for this problem. For other parameters and the network structure, we can start with two relu-activated layers with **100 neurons** and go from there.\n",
    "\n",
    "1. Define your model using \"Sequential()\".\n",
    "2. Define your optimizer using the Adam optimizer from keras, and use the default learning rate of 0.001.\n",
    "3. Add an input layer and specify a size of 100 neurons (size=number of original features).\n",
    "4. Add one hidden layer and specify 100 neurons.\n",
    "5. Add an output layer with one neuron\n",
    "6. Finally, compile your model using MSE as the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layer\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# Define the rest of the model architecture\n",
    "model = keras.Sequential([\n",
    "    Dense(100, activation='relu'),  # First hidden layer\n",
    "    Dense(100, activation='relu'),  # Second hidden layer\n",
    "    Dense(1, activation='linear')   # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_pO8Jjl_Q06"
   },
   "source": [
    "To create your neural network, fit your model and use 100 epochs and batch size = 300:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17829,
     "status": "ok",
     "timestamp": 1685403046028,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "EpC58myL_Q06",
    "outputId": "dba21fd1-fc42-4061-d3f0-33095bc5a504",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5224 - val_loss: 0.2985\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2501 - val_loss: 0.1402\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1345 - val_loss: 0.0790\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0791 - val_loss: 0.0483\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0568 - val_loss: 0.0393\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0496 - val_loss: 0.0372\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0439 - val_loss: 0.0361\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0499 - val_loss: 0.0353\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0386 - val_loss: 0.0347\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0472 - val_loss: 0.0343\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0355 - val_loss: 0.0341\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0339 - val_loss: 0.0342\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0423 - val_loss: 0.0333\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0421 - val_loss: 0.0332\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0328\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0369 - val_loss: 0.0331\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0372 - val_loss: 0.0326\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0451 - val_loss: 0.0332\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0380 - val_loss: 0.0326\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0276 - val_loss: 0.0321\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0327 - val_loss: 0.0322\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0359 - val_loss: 0.0330\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0351 - val_loss: 0.0325\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0304 - val_loss: 0.0320\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0337 - val_loss: 0.0319\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0267 - val_loss: 0.0328\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0272 - val_loss: 0.0326\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0315 - val_loss: 0.0324\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0361 - val_loss: 0.0317\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0326 - val_loss: 0.0326\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0287 - val_loss: 0.0320\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0289 - val_loss: 0.0323\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0330\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0271 - val_loss: 0.0321\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0273 - val_loss: 0.0326\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0283 - val_loss: 0.0322\n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0271 - val_loss: 0.0319\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0234 - val_loss: 0.0323\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0331\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0323\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0292 - val_loss: 0.0337\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0289 - val_loss: 0.0330\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0321 - val_loss: 0.0333\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0252 - val_loss: 0.0321\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0242 - val_loss: 0.0324\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0257 - val_loss: 0.0333\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0279 - val_loss: 0.0333\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0249 - val_loss: 0.0330\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0283 - val_loss: 0.0332\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0229 - val_loss: 0.0331\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0272 - val_loss: 0.0322\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0264 - val_loss: 0.0329\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0242 - val_loss: 0.0329\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0253 - val_loss: 0.0332\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0219 - val_loss: 0.0320\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0225 - val_loss: 0.0353\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0228 - val_loss: 0.0327\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0219 - val_loss: 0.0345\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0266 - val_loss: 0.0338\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0253 - val_loss: 0.0325\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0257 - val_loss: 0.0325\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0216 - val_loss: 0.0329\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0252 - val_loss: 0.0336\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0216 - val_loss: 0.0340\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0248 - val_loss: 0.0315\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0239 - val_loss: 0.0325\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0246 - val_loss: 0.0319\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0225 - val_loss: 0.0330\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0257 - val_loss: 0.0337\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0192 - val_loss: 0.0325\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0228 - val_loss: 0.0315\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0247 - val_loss: 0.0316\n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0218 - val_loss: 0.0318\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0246 - val_loss: 0.0327\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0215 - val_loss: 0.0322\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0239 - val_loss: 0.0335\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0241 - val_loss: 0.0315\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0237 - val_loss: 0.0311\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0219 - val_loss: 0.0329\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0293 - val_loss: 0.0312\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0240 - val_loss: 0.0316\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0293 - val_loss: 0.0313\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0220 - val_loss: 0.0327\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0232 - val_loss: 0.0341\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0249 - val_loss: 0.0316\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0215 - val_loss: 0.0316\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0215 - val_loss: 0.0315\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0196 - val_loss: 0.0297\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0261 - val_loss: 0.0340\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0236 - val_loss: 0.0302\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0185 - val_loss: 0.0323\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0218 - val_loss: 0.0316\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0232 - val_loss: 0.0311\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0271 - val_loss: 0.0311\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0218 - val_loss: 0.0289\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0195 - val_loss: 0.0316\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0189 - val_loss: 0.0315\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0190 - val_loss: 0.0311\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0204 - val_loss: 0.0297\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0227 - val_loss: 0.0326\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=300,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use \"model.evaluate\" to find the MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1685403046029,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "R9F0vSIG_Q07",
    "outputId": "3acbecba-51eb-471b-ba8d-7b9f98ea56d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0267\n",
      "Mean Squared Error: 0.026555519551038742\n"
     ]
    }
   ],
   "source": [
    "mse = model.evaluate(X_test,y_test)\n",
    "print('Mean Squared Error:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6o1--T2H_Q07"
   },
   "source": [
    "## Step 3\n",
    "\n",
    "As in the previous lab, we can plot the loss as a function of epoch from the train and validation data sets. Here the loss is of course the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 982
    },
    "executionInfo": {
     "elapsed": 938,
     "status": "ok",
     "timestamp": 1685403046962,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "igJTaSwy_Q07",
    "outputId": "0375ff29-c1c5-4e19-850c-f88c516407cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x229de6cad00>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Npn26F0Uo0X3"
   },
   "source": [
    "As always with regression problems, it is helpful to plot the predictions against the true values. Plot estimated redshift versus true redshift in a scatter plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3269,
     "status": "ok",
     "timestamp": 1685403054362,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "4j5LEBae_Q07",
    "outputId": "19fe2018-555e-4779-96a8-4ede8522a99f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.title('Estimated Redshift vs True Redshift')\n",
    "plt.xlabel('True Redshift')\n",
    "plt.ylabel('Estimated Redshift')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AISbbpfKo-nn"
   },
   "source": [
    "## Step 4\n",
    "\n",
    "We didn't do cross validation, so we can only generate predictions on our single test fold in order to derive the other metrics we are interested in.\n",
    "\n",
    "First, calculate the Outlier Fraction (OLF):\n",
    "\n",
    "$\\mathrm{OLF} = \\mathrm{num}\\left ( \\frac{|\\Delta z|}{1+z_{\\mathrm{true}}} > 0.15 = \\mathrm{true} \\right)/N$\n",
    "\n",
    "*The numerator is the number of instances where $\\frac{|\\Delta z|}{1+z_{\\mathrm{true}}}>0.15$ is true. $N$ is the length of $y_{\\mathrm{test}}$.*\n",
    "\n",
    "We can also calculate the Normalized Median Absolute Deviation (NMAD):\n",
    "\n",
    "$\\sigma_{\\mathrm{NMAD}}=1.48 \\times \\mathrm{median}\\left ( \\frac{|\\Delta z|}{1+z_{\\mathrm{true}}}\\right )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1685403054567,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "jB8PgXsG_Q08",
    "outputId": "d0001149-d329-4b15-d9de-8fdda7ad1926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Fraction: 0.041347675199692145\n",
      "Normalized Median Absolute Deviation: 0.27178416047458553\n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute differences between predicted and actual values\n",
    "dz = np.abs(predictions.flatten() - y_test.values.flatten())\n",
    "\n",
    "# Identify outliers where actual values are greater than 0.15\n",
    "outliers = np.where(y_test.values.flatten() > 0.15, 1, 0)\n",
    "\n",
    "# Calculate the Outlier Fraction (OLF) for outliers\n",
    "OLF = np.sum(dz[outliers == 1] / (1 + y_test.values.flatten()[outliers == 1])) / len(y_test)\n",
    "\n",
    "# Calculate the Normalized Median Absolute Deviation (NMAD) for non-outliers\n",
    "NMAD = 1.48 * np.median(dz[outliers == 0] / (1 + y_test.values.flatten()[outliers == 0]))\n",
    "\n",
    "# Print the Outlier Fraction and Normalized Median Absolute Deviation\n",
    "print('Outlier Fraction:', OLF)\n",
    "print('Normalized Median Absolute Deviation:', NMAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Effect of loss function\n",
    "\n",
    "So far, we have used the MSE loss in our training, but this choice is not unique. Would using the MAE or MAPE loss functions give better results for the OLF and NMAD parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.7121 - val_loss: 0.4111\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3907 - val_loss: 0.3377\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3135 - val_loss: 0.2357\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2155 - val_loss: 0.1658\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1542 - val_loss: 0.1217\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1200 - val_loss: 0.1176\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1176 - val_loss: 0.1152\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1106 - val_loss: 0.1071\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1078 - val_loss: 0.1056\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1052 - val_loss: 0.1016\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0982 - val_loss: 0.1015\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0963 - val_loss: 0.1000\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0911 - val_loss: 0.0956\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0922 - val_loss: 0.0943\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0923 - val_loss: 0.0926\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0906 - val_loss: 0.0917\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0874 - val_loss: 0.0906\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0903 - val_loss: 0.0954\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0888 - val_loss: 0.0880\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0868 - val_loss: 0.0864\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0874 - val_loss: 0.0869\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0828 - val_loss: 0.0859\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0787 - val_loss: 0.0850\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0807 - val_loss: 0.0853\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0776 - val_loss: 0.0865\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0829 - val_loss: 0.0862\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0830 - val_loss: 0.0860\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0817 - val_loss: 0.0845\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0817 - val_loss: 0.0835\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0793 - val_loss: 0.0841\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0827 - val_loss: 0.0823\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0786 - val_loss: 0.0808\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0761 - val_loss: 0.0837\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0783 - val_loss: 0.0814\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0757 - val_loss: 0.0815\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0727 - val_loss: 0.0803\n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0832 - val_loss: 0.0799\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0748 - val_loss: 0.0784\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0701 - val_loss: 0.0773\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0721 - val_loss: 0.0802\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0749 - val_loss: 0.0784\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0749 - val_loss: 0.0767\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0696 - val_loss: 0.0775\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0712 - val_loss: 0.0760\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0727 - val_loss: 0.0756\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0728 - val_loss: 0.0778\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0734 - val_loss: 0.0767\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0694 - val_loss: 0.0798\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0722 - val_loss: 0.0787\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0694 - val_loss: 0.0752\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0685 - val_loss: 0.0770\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0716 - val_loss: 0.0741\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0705 - val_loss: 0.0731\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0696 - val_loss: 0.0749\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0672 - val_loss: 0.0740\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0693 - val_loss: 0.0775\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0683 - val_loss: 0.0763\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0683 - val_loss: 0.0739\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0678 - val_loss: 0.0725\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0663 - val_loss: 0.0769\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0712 - val_loss: 0.0757\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0696 - val_loss: 0.0726\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0715 - val_loss: 0.0736\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0675 - val_loss: 0.0726\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0639 - val_loss: 0.0723\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0694 - val_loss: 0.0715\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0671 - val_loss: 0.0722\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0660 - val_loss: 0.0715\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0666 - val_loss: 0.0709\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0669 - val_loss: 0.0709\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0663 - val_loss: 0.0714\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0660 - val_loss: 0.0711\n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0624 - val_loss: 0.0705\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0694 - val_loss: 0.0706\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0676 - val_loss: 0.0706\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0645 - val_loss: 0.0740\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0693 - val_loss: 0.0716\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0665 - val_loss: 0.0707\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0639 - val_loss: 0.0711\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0633 - val_loss: 0.0713\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0648 - val_loss: 0.0693\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0637 - val_loss: 0.0700\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0643 - val_loss: 0.0698\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0653 - val_loss: 0.0707\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0671 - val_loss: 0.0733\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0641 - val_loss: 0.0717\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0638 - val_loss: 0.0708\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0637 - val_loss: 0.0700\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0649 - val_loss: 0.0679\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0643 - val_loss: 0.0699\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0661 - val_loss: 0.0687\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0635 - val_loss: 0.0707\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0660 - val_loss: 0.0682\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0591 - val_loss: 0.0682\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0642 - val_loss: 0.0689\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0619 - val_loss: 0.0680\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0616 - val_loss: 0.0672\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0640 - val_loss: 0.0672\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0618 - val_loss: 0.0692\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0655 - val_loss: 0.0695\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.0667\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss Function: mean_absolute_error\n",
      "Outlier Fraction (OLF): 0.03341012255309768\n",
      "Normalized Median Absolute Deviation (NMAD): 0.07738495379393985\n",
      "--------------------------------------------------\n",
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 144.6363 - val_loss: 14.9294\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.3225 - val_loss: 15.5607\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22.4211 - val_loss: 22.6015\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.7141 - val_loss: 22.8152\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 127.5729 - val_loss: 23.1316\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 53.2369 - val_loss: 20.8920\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 206.0739 - val_loss: 21.1590\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.8465 - val_loss: 17.0617\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 42.4617 - val_loss: 17.1716\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.1944 - val_loss: 16.5733\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 51.8644 - val_loss: 17.0898\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.3253 - val_loss: 16.5539\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.7235 - val_loss: 16.9288\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.4852 - val_loss: 20.8453\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 90.5920 - val_loss: 17.6054\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 23.7355 - val_loss: 18.0427\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 61.4067 - val_loss: 16.5419\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.0815 - val_loss: 16.9316\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 52.3974 - val_loss: 17.6356\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26.5922 - val_loss: 18.4989\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.0382 - val_loss: 15.7190\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.3180 - val_loss: 15.6007\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39.0330 - val_loss: 15.0770\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 49.2767 - val_loss: 16.0764\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.4549 - val_loss: 14.9959\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.7676 - val_loss: 17.0429\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.9093 - val_loss: 14.7777\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.0854 - val_loss: 13.8229\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.0384 - val_loss: 13.5775\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.8824 - val_loss: 14.9313\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.3687 - val_loss: 14.3390\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 59.8462 - val_loss: 14.4925\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.0408 - val_loss: 13.4283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 93.6731 - val_loss: 14.6078\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.4954 - val_loss: 14.2891\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 52.1179 - val_loss: 13.5447\n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 79.5295 - val_loss: 15.1213\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.6251 - val_loss: 13.7372\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.9865 - val_loss: 13.4330\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.4769 - val_loss: 15.7319\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 53.3179 - val_loss: 15.2874\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.4807 - val_loss: 13.5421\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.2187 - val_loss: 13.3999\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25.3460 - val_loss: 16.3366\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.0842 - val_loss: 17.7563\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 51.5957 - val_loss: 16.2931\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.4131 - val_loss: 15.8624\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.6549 - val_loss: 17.2121\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.2324 - val_loss: 14.5503\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 213.5840 - val_loss: 12.8884\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1900 - val_loss: 14.5628\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.3313 - val_loss: 13.6501\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.3226 - val_loss: 13.5921\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1452 - val_loss: 16.9694\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 42.2639 - val_loss: 17.9861\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 78.6582 - val_loss: 14.3571\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.7546 - val_loss: 13.8779\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.4844 - val_loss: 15.6775\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 42.0891 - val_loss: 14.5467\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.4264 - val_loss: 14.1721\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 100.6595 - val_loss: 14.9531\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.2677 - val_loss: 14.9549\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 46.5996 - val_loss: 14.3489\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.4502 - val_loss: 16.7201\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.1438 - val_loss: 15.2537\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.8317 - val_loss: 13.7757\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 23.2831 - val_loss: 12.6465\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.3120 - val_loss: 16.7101\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 59.0179 - val_loss: 18.4669\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45.1373 - val_loss: 15.7191\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.1707 - val_loss: 15.0842\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.4485 - val_loss: 13.9327\n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.1758 - val_loss: 13.5277\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.2921 - val_loss: 14.9940\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22.9587 - val_loss: 14.9318\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.3200 - val_loss: 13.3802\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.7060 - val_loss: 13.7988\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.9191 - val_loss: 12.5481\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3801 - val_loss: 12.8400\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 53.0842 - val_loss: 14.3249\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 68.3008 - val_loss: 14.3330\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.3990 - val_loss: 12.8985\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 34.3694 - val_loss: 12.5066\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.5504 - val_loss: 13.9804\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.4145 - val_loss: 13.1495\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.5112 - val_loss: 13.6128\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24.7326 - val_loss: 13.2539\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 47.2680 - val_loss: 13.8829\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.7695 - val_loss: 13.7795\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 34.8462 - val_loss: 13.2737\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.0542 - val_loss: 13.1735\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 50.9525 - val_loss: 12.7800\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.0479 - val_loss: 14.3168\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 133.6325 - val_loss: 14.8459\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 41.3418 - val_loss: 14.3405\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.1104 - val_loss: 14.7653\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.5905 - val_loss: 13.6210\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.5942 - val_loss: 14.7189\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.2528 - val_loss: 13.1484\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25.3510 - val_loss: 11.8035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.2348\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss Function: mean_absolute_percentage_error\n",
      "Outlier Fraction (OLF): 0.0412961798874154\n",
      "Normalized Median Absolute Deviation (NMAD): 0.05796764035800236\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the neural network\n",
    "model = Sequential([\n",
    "    Dense(100, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# For each loss function: MAE and MAPE\n",
    "for loss_function in ['mean_absolute_error', 'mean_absolute_percentage_error']:\n",
    "    # Compile the model with Adam optimizer and the selected loss function\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_function)\n",
    "    \n",
    "    #train\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=300, validation_data=(X_val, y_val))\n",
    "    \n",
    "    # Evaluate \n",
    "    model.evaluate(X_test, y_test)\n",
    "    \n",
    "    # Predictions on test data\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Absolute differences between predictions and actual values\n",
    "    dz = np.abs(predictions.flatten() - y_test.values.flatten())\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers = np.where(y_test.values.flatten() > 0.15, 1, 0)\n",
    "    \n",
    "    # Calculate OLF for outliers\n",
    "    OLF = np.sum(dz[outliers == 1] / (1 + y_test.values.flatten()[outliers == 1])) / len(y_test)\n",
    "    \n",
    "    # Calculate NMAD for non-outliers\n",
    "    NMAD = 1.48 * np.median(dz[outliers == 0] / (1 + y_test.values.flatten()[outliers == 0]))\n",
    "    \n",
    "    print('Loss Function:'loss_function)\n",
    "    print('Outlier Fraction (OLF):', OLF)\n",
    "    print('Normalized Median Absolute Deviation (NMAD):', NMAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE loss gives the better overall results for the OLF and NMAD parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Effect of learning rate schedules\n",
    "\n",
    "When training a neural network, we can tune the performance by optimizing a large set of hyperparameters. Last time, we looked at the choice of optimizer and regularization. Another important parameter is the learning rate. A learning rate that is set too small will slow down the training, as we update the weights of the network in tiny steps. On the other hand, if the learning rate is set too high, the training can diverge. Usually we want to start with a large learning rate to make fast progress and then slow down the training close to the optimum. This can be achieved by using learning rate schedules, which we will investigate in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Time based-decay\n",
    "\n",
    "First we can try a time-based decay:\n",
    "$$\\eta(t)=\\eta_0/(1+t⋅\\eta_0/n_{epochs})$$\n",
    "\n",
    "where $\\eta_0$ is the initial learning rate, $t$ the iteration number (epoch) and $n_{epochs}$ the total number of epochs. \n",
    "\n",
    "Write a function (i.e the learning schedule) that implements this learning schedule. The function takes an epoch index (integer, indexed from 0) and current learning rate (float) as inputs and returns a new learning rate as output (float). In our case, the current learning rate is not actually used in the function, but this format is expected when we use it in keras later. Set the initial learning rate to 0.001 and the number of epochs to 100. Make a plot of the learning rate as a function of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_based_decay(epoch, cur_lr):\n",
    "    init_lr = 0.001\n",
    "    epochs = 100\n",
    "    decay_rate = init_lr / epochs\n",
    "    new_lr = init_lr / (1 + epoch * decay_rate)\n",
    "    return new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Learning Rate')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs=range(100)\n",
    "learning_rates=[time_based_decay(epoch, 0) for epoch in epochs]\n",
    "plt.plot(epochs,learning_rates)\n",
    "plt.title('Learning Rate Schedule: Time-based Decay')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with this new learning rate schedule, and save the history. Remember to rebuild the model to re-initialize all weights and biases. To use the learning rate schedule, add **callbacks=[keras.callbacks.LearningRateScheduler(my_function, verbose=1)]** to model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.4148 - val_loss: 0.2563 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0009999900000999989.\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2079 - val_loss: 0.1362 - learning_rate: 9.9999e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.000999980000399992.\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1078 - val_loss: 0.0779 - learning_rate: 9.9998e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.000999970000899973.\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0591 - val_loss: 0.0614 - learning_rate: 9.9997e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.000999960001599936.\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0481 - val_loss: 0.0559 - learning_rate: 9.9996e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.000999950002499875.\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0418 - val_loss: 0.0549 - learning_rate: 9.9995e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.000999940003599784.\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0472 - val_loss: 0.0549 - learning_rate: 9.9994e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.000999930004899657.\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0457 - val_loss: 0.0534 - learning_rate: 9.9993e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.000999920006399488.\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0445 - val_loss: 0.0527 - learning_rate: 9.9992e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0009999100080992712.\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0435 - val_loss: 0.0522 - learning_rate: 9.9991e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.000999900009999.\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0397 - val_loss: 0.0520 - learning_rate: 9.9990e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.000999890012098669.\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0429 - val_loss: 0.0511 - learning_rate: 9.9989e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0009998800143982724.\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0422 - val_loss: 0.0508 - learning_rate: 9.9988e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0009998700168978034.\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0395 - val_loss: 0.0514 - learning_rate: 9.9987e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0009998600195972563.\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0358 - val_loss: 0.0505 - learning_rate: 9.9986e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0009998500224966255.\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0333 - val_loss: 0.0499 - learning_rate: 9.9985e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0009998400255959048.\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0341 - val_loss: 0.0498 - learning_rate: 9.9984e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0009998300288950879.\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0499 - learning_rate: 9.9983e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.000999820032394169.\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0353 - val_loss: 0.0496 - learning_rate: 9.9982e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0009998100360931424.\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0331 - val_loss: 0.0494 - learning_rate: 9.9981e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0009998000399920016.\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.0492 - learning_rate: 9.9980e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000999790044090741.\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0485 - learning_rate: 9.9979e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0009997800483893542.\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0480 - learning_rate: 9.9978e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.000999770052887836.\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0302 - val_loss: 0.0483 - learning_rate: 9.9977e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0009997600575861792.\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0327 - val_loss: 0.0490 - learning_rate: 9.9976e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0009997500624843788.\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0324 - val_loss: 0.0481 - learning_rate: 9.9975e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0009997400675824286.\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0480 - learning_rate: 9.9974e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0009997300728803223.\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0480 - learning_rate: 9.9973e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0009997200783780542.\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0344 - val_loss: 0.0480 - learning_rate: 9.9972e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0009997100840756182.\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0287 - val_loss: 0.0477 - learning_rate: 9.9971e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.000999700089973008.\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0321 - val_loss: 0.0477 - learning_rate: 9.9970e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0009996900960702183.\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0469 - learning_rate: 9.9969e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0009996801023672425.\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0406 - val_loss: 0.0476 - learning_rate: 9.9968e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.000999670108864075.\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.0470 - learning_rate: 9.9967e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0009996601155607093.\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0309 - val_loss: 0.0472 - learning_rate: 9.9966e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0009996501224571398.\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0471 - learning_rate: 9.9965e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0009996401295533609.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0469 - learning_rate: 9.9964e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0009996301368493659.\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0479 - learning_rate: 9.9963e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0009996201443451488.\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0349 - val_loss: 0.0487 - learning_rate: 9.9962e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0009996101520407042.\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0471 - learning_rate: 9.9961e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0009996001599360256.\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0338 - val_loss: 0.0469 - learning_rate: 9.9960e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.0009995901680311073.\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0309 - val_loss: 0.0467 - learning_rate: 9.9959e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0009995801763259431.\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0471 - learning_rate: 9.9958e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0009995701848205273.\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.0461 - learning_rate: 9.9957e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0009995601935148535.\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.0463 - learning_rate: 9.9956e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0009995502024089159.\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0474 - learning_rate: 9.9955e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.000999540211502709.\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0274 - val_loss: 0.0459 - learning_rate: 9.9954e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.000999530220796226.\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0316 - val_loss: 0.0461 - learning_rate: 9.9953e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.000999520230289461.\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0314 - val_loss: 0.0463 - learning_rate: 9.9952e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.0009995102399824086.\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0269 - val_loss: 0.0456 - learning_rate: 9.9951e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.0009995002498750627.\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0325 - val_loss: 0.0456 - learning_rate: 9.9950e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.0009994902599674165.\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0461 - learning_rate: 9.9949e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.000999480270259465.\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0283 - val_loss: 0.0467 - learning_rate: 9.9948e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.000999470280751202.\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0459 - learning_rate: 9.9947e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.000999460291442621.\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0268 - val_loss: 0.0470 - learning_rate: 9.9946e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.0009994503023337165.\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0454 - learning_rate: 9.9945e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.0009994403134244824.\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0228 - val_loss: 0.0469 - learning_rate: 9.9944e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0009994303247149127.\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0462 - learning_rate: 9.9943e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.0009994203362050011.\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0242 - val_loss: 0.0474 - learning_rate: 9.9942e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.000999410347894742.\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0252 - val_loss: 0.0457 - learning_rate: 9.9941e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.0009994003597841297.\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0279 - val_loss: 0.0457 - learning_rate: 9.9940e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.0009993903718731574.\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0244 - val_loss: 0.0452 - learning_rate: 9.9939e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.0009993803841618196.\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0447 - learning_rate: 9.9938e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.0009993703966501106.\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0446 - learning_rate: 9.9937e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.0009993604093380237.\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0455 - learning_rate: 9.9936e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.0009993504222255533.\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0455 - learning_rate: 9.9935e-04\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.0009993404353126935.\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0303 - val_loss: 0.0447 - learning_rate: 9.9934e-04\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.0009993304485994385.\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0443 - learning_rate: 9.9933e-04\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.0009993204620857817.\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0222 - val_loss: 0.0462 - learning_rate: 9.9932e-04\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.0009993104757717174.\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0454 - learning_rate: 9.9931e-04\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.00099930048965724.\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0245 - val_loss: 0.0452 - learning_rate: 9.9930e-04\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.0009992905037423429.\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0258 - val_loss: 0.0454 - learning_rate: 9.9929e-04\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.0009992805180270205.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0262 - val_loss: 0.0489 - learning_rate: 9.9928e-04\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.0009992705325112669.\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0313 - val_loss: 0.0455 - learning_rate: 9.9927e-04\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.0009992605471950758.\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0231 - val_loss: 0.0448 - learning_rate: 9.9926e-04\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.0009992505620784412.\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0217 - val_loss: 0.0452 - learning_rate: 9.9925e-04\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.0009992405771613573.\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0270 - val_loss: 0.0452 - learning_rate: 9.9924e-04\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.0009992305924438184.\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0453 - learning_rate: 9.9923e-04\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.0009992206079258179.\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0461 - learning_rate: 9.9922e-04\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.0009992106236073502.\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0268 - val_loss: 0.0454 - learning_rate: 9.9921e-04\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.0009992006394884093.\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0226 - val_loss: 0.0451 - learning_rate: 9.9920e-04\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.0009991906555689891.\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0254 - val_loss: 0.0464 - learning_rate: 9.9919e-04\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.0009991806718490836.\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0466 - learning_rate: 9.9918e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.0009991706883286872.\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0263 - val_loss: 0.0457 - learning_rate: 9.9917e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.0009991607050077935.\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0255 - val_loss: 0.0462 - learning_rate: 9.9916e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.0009991507218863967.\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0258 - val_loss: 0.0452 - learning_rate: 9.9915e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.0009991407389644904.\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0274 - val_loss: 0.0451 - learning_rate: 9.9914e-04\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.0009991307562420696.\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0449 - learning_rate: 9.9913e-04\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.0009991207737191272.\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0210 - val_loss: 0.0452 - learning_rate: 9.9912e-04\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.0009991107913956579.\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0210 - val_loss: 0.0457 - learning_rate: 9.9911e-04\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.0009991008092716557.\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0457 - learning_rate: 9.9910e-04\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.0009990908273471142.\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0205 - val_loss: 0.0456 - learning_rate: 9.9909e-04\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.0009990808456220278.\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0257 - val_loss: 0.0450 - learning_rate: 9.9908e-04\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 0.0009990708640963903.\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0254 - val_loss: 0.0461 - learning_rate: 9.9907e-04\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.000999060882770196.\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0225 - val_loss: 0.0461 - learning_rate: 9.9906e-04\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.0009990509016434388.\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0212 - val_loss: 0.0458 - learning_rate: 9.9905e-04\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.0009990409207161124.\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0185 - val_loss: 0.0441 - learning_rate: 9.9904e-04\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.0009990309399882115.\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0217 - val_loss: 0.0457 - learning_rate: 9.9903e-04\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.0009990209594597295.\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0244 - val_loss: 0.0459 - learning_rate: 9.9902e-04\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.0009990109791306607.\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0217 - val_loss: 0.0456 - learning_rate: 9.9901e-04\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(100, activation='relu',input_dim=X_train.shape[1]),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "lr_schedule = keras.callbacks.LearningRateScheduler(time_based_decay, verbose=1)\n",
    "\n",
    "history_t = model.fit(X_train,\n",
    "                                y_train, epochs=100, \n",
    "                                batch_size=300, \n",
    "                                validation_data=(X_val, y_val), \n",
    "                                callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exponential decay\n",
    "\n",
    "Repeat Part 3 Step 1 for a different learning schedule that uses exponential decay,\n",
    "\n",
    "$$ \\eta(t)=\\eta_0⋅e^{−k⋅t},$$\n",
    "\n",
    "where $k$ is the decay rate. We can try k=0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(epoch, lr):\n",
    "    initial_lr = 0.001\n",
    "    k = 0.01\n",
    "    new_lr = initial_lr * np.exp(-k * epoch)\n",
    "    return new_lr\n",
    "\n",
    "epochs=np.arange(100)\n",
    "lr=0.001\n",
    "learning_rates = [exponential_decay(epoch, lr) for epoch in epochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, learning_rates)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Exponential Decay Learning Rate Schedule')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.4306 - val_loss: 0.2464 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.000990049833749168.\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1914 - val_loss: 0.1202 - learning_rate: 9.9005e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0009801986733067552.\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0921 - val_loss: 0.0782 - learning_rate: 9.8020e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0009704455335485082.\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0697 - val_loss: 0.0607 - learning_rate: 9.7045e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0009607894391523232.\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0441 - val_loss: 0.0562 - learning_rate: 9.6079e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.000951229424500714.\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0391 - val_loss: 0.0563 - learning_rate: 9.5123e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0009417645335842487.\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0437 - val_loss: 0.0548 - learning_rate: 9.4176e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0009323938199059483.\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0426 - val_loss: 0.0543 - learning_rate: 9.3239e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0009231163463866358.\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0390 - val_loss: 0.0533 - learning_rate: 9.2312e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0009139311852712283.\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0490 - val_loss: 0.0530 - learning_rate: 9.1393e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009048374180359595.\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0487 - val_loss: 0.0525 - learning_rate: 9.0484e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0008958341352965282.\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0391 - val_loss: 0.0513 - learning_rate: 8.9583e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008869204367171575.\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0487 - val_loss: 0.0514 - learning_rate: 8.8692e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008780954309205613.\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0325 - val_loss: 0.0508 - learning_rate: 8.7810e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0008693582353988059.\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0358 - val_loss: 0.0507 - learning_rate: 8.6936e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0008607079764250578.\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0379 - val_loss: 0.0507 - learning_rate: 8.6071e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0008521437889662113.\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0334 - val_loss: 0.0505 - learning_rate: 8.5214e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0008436648165963838.\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0465 - val_loss: 0.0511 - learning_rate: 8.4366e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.000835270211411272.\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0388 - val_loss: 0.0506 - learning_rate: 8.3527e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0008269591339433623.\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0399 - val_loss: 0.0496 - learning_rate: 8.2696e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0008187307530779819.\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0343 - val_loss: 0.0495 - learning_rate: 8.1873e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0008105842459701871.\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0346 - val_loss: 0.0501 - learning_rate: 8.1058e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0008025187979624785.\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0380 - val_loss: 0.0500 - learning_rate: 8.0252e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.000794533602503334.\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0490 - learning_rate: 7.9453e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0007866278610665535.\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0401 - val_loss: 0.0487 - learning_rate: 7.8663e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0007788007830714049.\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0328 - val_loss: 0.0487 - learning_rate: 7.7880e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0007710515858035663.\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0491 - learning_rate: 7.7105e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0007633794943368531.\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0288 - val_loss: 0.0493 - learning_rate: 7.6338e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0007557837414557255.\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0356 - val_loss: 0.0483 - learning_rate: 7.5578e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0007482635675785653.\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0320 - val_loss: 0.0481 - learning_rate: 7.4826e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0007408182206817179.\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0340 - val_loss: 0.0482 - learning_rate: 7.4082e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0007334469562242892.\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0479 - learning_rate: 7.3345e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.000726149037073691.\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0478 - learning_rate: 7.2615e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0007189237334319262.\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0472 - learning_rate: 7.1892e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0007117703227626096.\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.0472 - learning_rate: 7.1177e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0007046880897187134.\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0336 - val_loss: 0.0472 - learning_rate: 7.0469e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.000697676326071031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0371 - val_loss: 0.0470 - learning_rate: 6.9768e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0006907343306373547.\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0319 - val_loss: 0.0470 - learning_rate: 6.9073e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0006838614092123559.\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0292 - val_loss: 0.0466 - learning_rate: 6.8386e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0006770568744981646.\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0319 - val_loss: 0.0476 - learning_rate: 6.7706e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0006703200460356394.\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0297 - val_loss: 0.0466 - learning_rate: 6.7032e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.0006636502501363194.\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0467 - learning_rate: 6.6365e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0006570468198150568.\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0293 - val_loss: 0.0463 - learning_rate: 6.5705e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006505090947233165.\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0466 - learning_rate: 6.5051e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006440364210831414.\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0471 - learning_rate: 6.4404e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0006376281516217733.\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0341 - val_loss: 0.0473 - learning_rate: 6.3763e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.000631283645506926.\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0287 - val_loss: 0.0497 - learning_rate: 6.3128e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0006250022682827008.\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0306 - val_loss: 0.0469 - learning_rate: 6.2500e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0006187833918061408.\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0304 - val_loss: 0.0472 - learning_rate: 6.1878e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.0006126263941844161.\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0295 - val_loss: 0.0464 - learning_rate: 6.1263e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.0006065306597126335.\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0265 - val_loss: 0.0466 - learning_rate: 6.0653e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.000600495578812266.\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.0471 - learning_rate: 6.0050e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0005945205479701944.\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0462 - learning_rate: 5.9452e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.0005886049696783552.\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0301 - val_loss: 0.0471 - learning_rate: 5.8860e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0005827482523739897.\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0461 - learning_rate: 5.8275e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.0005769498103804867.\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0271 - val_loss: 0.0467 - learning_rate: 5.7695e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.0005712090638488148.\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0275 - val_loss: 0.0474 - learning_rate: 5.7121e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0005655254386995371.\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0266 - val_loss: 0.0460 - learning_rate: 5.6553e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.000559898366565402.\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0298 - val_loss: 0.0456 - learning_rate: 5.5990e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.0005543272847345071.\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0266 - val_loss: 0.0453 - learning_rate: 5.5433e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.0005488116360940265.\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0274 - val_loss: 0.0457 - learning_rate: 5.4881e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.0005433508690744998.\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0329 - val_loss: 0.0460 - learning_rate: 5.4335e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.0005379444375946745.\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0264 - val_loss: 0.0458 - learning_rate: 5.3794e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.0005325918010068972.\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0313 - val_loss: 0.0458 - learning_rate: 5.3259e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.0005272924240430486.\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0454 - learning_rate: 5.2729e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.000522045776761016.\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0449 - learning_rate: 5.2205e-04\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.0005168513344916992.\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0263 - val_loss: 0.0456 - learning_rate: 5.1685e-04\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.0005117085777865425.\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0456 - learning_rate: 5.1171e-04\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.0005066169923655895.\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.0450 - learning_rate: 5.0662e-04\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.0005015760690660555.\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0258 - val_loss: 0.0449 - learning_rate: 5.0158e-04\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.0004965853037914095.\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0297 - val_loss: 0.0454 - learning_rate: 4.9659e-04\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.0004916441974609651.\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0215 - val_loss: 0.0449 - learning_rate: 4.9164e-04\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.0004867522559599717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0456 - learning_rate: 4.8675e-04\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.00048190899009020245.\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0252 - val_loss: 0.0450 - learning_rate: 4.8191e-04\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.0004771139155210344.\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0250 - val_loss: 0.0446 - learning_rate: 4.7711e-04\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.0004723665527410147.\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0253 - val_loss: 0.0447 - learning_rate: 4.7237e-04\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.00046766642700990925.\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0290 - val_loss: 0.0447 - learning_rate: 4.6767e-04\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.00046301306831122806.\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0445 - learning_rate: 4.6301e-04\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.00045840601130522354.\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0454 - learning_rate: 4.5841e-04\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.0004538447952823558.\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0323 - val_loss: 0.0447 - learning_rate: 4.5384e-04\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.0004493289641172216.\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0284 - val_loss: 0.0447 - learning_rate: 4.4933e-04\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.0004448580662229411.\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0440 - learning_rate: 4.4486e-04\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.0004404316545059993.\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0440 - learning_rate: 4.4043e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.0004360492863215356.\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0237 - val_loss: 0.0448 - learning_rate: 4.3605e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.00043171052342907973.\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0447 - learning_rate: 4.3171e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.0004274149319487267.\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0445 - learning_rate: 4.2741e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.00042316208231774885.\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0236 - val_loss: 0.0443 - learning_rate: 4.2316e-04\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.000418951549247639.\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0241 - val_loss: 0.0437 - learning_rate: 4.1895e-04\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.0004147829116815814.\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0253 - val_loss: 0.0436 - learning_rate: 4.1478e-04\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.0004106557527523455.\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0262 - val_loss: 0.0441 - learning_rate: 4.1066e-04\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.00040656965974059914.\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0289 - val_loss: 0.0437 - learning_rate: 4.0657e-04\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.00040252422403363596.\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0228 - val_loss: 0.0437 - learning_rate: 4.0252e-04\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.00039851904108451417.\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0246 - val_loss: 0.0439 - learning_rate: 3.9852e-04\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 0.0003945537103716011.\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0270 - val_loss: 0.0440 - learning_rate: 3.9455e-04\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.00039062783535852107.\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0256 - val_loss: 0.0430 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.00038674102345450116.\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0266 - val_loss: 0.0437 - learning_rate: 3.8674e-04\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.0003828928859751121.\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0435 - learning_rate: 3.8289e-04\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.00037908303810339886.\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0329 - val_loss: 0.0441 - learning_rate: 3.7908e-04\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.0003753110988513996.\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0260 - val_loss: 0.0439 - learning_rate: 3.7531e-04\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.0003715766910220457.\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0275 - val_loss: 0.0434 - learning_rate: 3.7158e-04\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(100, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "lr_schedule = keras.callbacks.LearningRateScheduler(exponential_decay, verbose=1)\n",
    "\n",
    "history_exp = model.fit(X_train,\n",
    "                                y_train, epochs=100, \n",
    "                                batch_size=300, \n",
    "                                validation_data=(X_val, y_val), \n",
    "                                callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: \n",
    "\n",
    "Graph the loss for the three learning schedules we have (constant, time decay, exponential decay). Zoom in on the values at the end of the training to better see the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2240b09b3a0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],label='Constant LR Training')\n",
    "plt.plot(history.history['val_loss'],label='Constant LR Validation')\n",
    "plt.plot(history_t.history['loss'], label='Time Decay LR Training')\n",
    "plt.plot(history_t.history['val_loss'], label='Time Decay LR Validation')\n",
    "plt.plot(history_exp.history['loss'], label='Exponential Decay LR Training')\n",
    "plt.plot(history_exp.history['val_loss'], label='Exponential Decay LR Validation')\n",
    "\n",
    "plt.xlim(90,100)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Comparison')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: A first convolutional neural network\n",
    "\n",
    "In the following, we try to improve on our dense NN for the MNIST image dataset with a deep convolutional network. There are two new kinds of layers that will be used, **Conv2D** and **MaxPool2D**. We will discuss this in detail next week, but for now just look at the code. While the code runs, try to figure out the structure of the network. You might want to look up these layers in the keras documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (50000, 28, 28, 1)\n",
      "y_train.shape = (50000,)\n",
      "x_val.shape = (10000, 28, 28, 1)\n",
      "y_val.shape = (10000,)\n",
      "x_test.shape = (10000, 28, 28, 1)\n",
      "y_test.shape = (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  \n",
    "\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "\tx_train, y_train, test_size = 1/6, random_state=42)\n",
    "\n",
    "print('x_train.shape =', x_train.shape)\n",
    "print('y_train.shape =', y_train.shape)\n",
    "print('x_val.shape =', x_val.shape)\n",
    "print('y_val.shape =', y_val.shape)\n",
    "print('x_test.shape =', x_test.shape)\n",
    "print('y_test.shape =', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\antho\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,510</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1960</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">125,504</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │           \u001b[38;5;34m260\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │         \u001b[38;5;34m2,510\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1960\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_97 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m125,504\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_98 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,924</span> (503.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m128,924\u001b[0m (503.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,924</span> (503.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m128,924\u001b[0m (503.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_34\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_34\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_101 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "def make_conv_model():\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Conv2D(filters = 10, kernel_size = (5,5),padding = 'Same', \n",
    "                  activation ='relu', input_shape = (28,28,1)))\n",
    "  model.add(Conv2D(filters = 10, kernel_size = (5,5),padding = 'Same', \n",
    "                  activation ='relu'))\n",
    "  model.add(MaxPool2D(pool_size=(2,2)))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(64, activation = \"relu\"))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(10, activation = \"softmax\"))\n",
    "  optimizer = keras.optimizers.Adam()\n",
    "\n",
    "  model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']) \n",
    "  return model\n",
    "\n",
    "def make_dense_model():\n",
    "  model = Sequential()\n",
    "  model.add(Flatten(input_shape = (28,28,1)))\n",
    "  model.add(Dense(512, activation = \"relu\"))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(256, activation = \"relu\"))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(10, activation = \"softmax\"))\n",
    "  optimizer = keras.optimizers.Adam()\n",
    "\n",
    "  model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']) \n",
    "  return model\n",
    "\n",
    "simple_conv_model = make_conv_model()\n",
    "dense_model = make_dense_model()\n",
    "simple_conv_model.summary()\n",
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8440 - loss: 0.5171 - val_accuracy: 0.9788 - val_loss: 0.0725\n",
      "Epoch 2/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 24ms/step - accuracy: 0.9721 - loss: 0.0922 - val_accuracy: 0.9820 - val_loss: 0.0542\n",
      "Epoch 3/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 24ms/step - accuracy: 0.9806 - loss: 0.0620 - val_accuracy: 0.9857 - val_loss: 0.0481\n",
      "Epoch 4/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - accuracy: 0.9852 - loss: 0.0478 - val_accuracy: 0.9883 - val_loss: 0.0403\n",
      "Epoch 5/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9864 - loss: 0.0425 - val_accuracy: 0.9888 - val_loss: 0.0383\n",
      "Epoch 6/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.9896 - loss: 0.0325 - val_accuracy: 0.9887 - val_loss: 0.0390\n",
      "Epoch 7/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - accuracy: 0.9907 - loss: 0.0302 - val_accuracy: 0.9876 - val_loss: 0.0447\n",
      "Epoch 8/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.9912 - loss: 0.0266 - val_accuracy: 0.9889 - val_loss: 0.0424\n",
      "Epoch 9/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9918 - loss: 0.0262 - val_accuracy: 0.9889 - val_loss: 0.0408\n",
      "Epoch 10/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9930 - loss: 0.0203 - val_accuracy: 0.9863 - val_loss: 0.0489\n",
      "Epoch 11/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9928 - loss: 0.0193 - val_accuracy: 0.9895 - val_loss: 0.0417\n",
      "Epoch 12/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9927 - loss: 0.0193 - val_accuracy: 0.9896 - val_loss: 0.0429\n",
      "Epoch 13/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 32ms/step - accuracy: 0.9957 - loss: 0.0130 - val_accuracy: 0.9901 - val_loss: 0.0447\n",
      "Epoch 14/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0144 - val_accuracy: 0.9903 - val_loss: 0.0436\n",
      "Epoch 15/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9956 - loss: 0.0140 - val_accuracy: 0.9891 - val_loss: 0.0466\n",
      "Epoch 16/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9956 - loss: 0.0124 - val_accuracy: 0.9905 - val_loss: 0.0456\n",
      "Epoch 17/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9961 - loss: 0.0127 - val_accuracy: 0.9901 - val_loss: 0.0436\n",
      "Epoch 18/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0125 - val_accuracy: 0.9898 - val_loss: 0.0474\n",
      "Epoch 19/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9967 - loss: 0.0106 - val_accuracy: 0.9906 - val_loss: 0.0474\n",
      "Epoch 20/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9961 - loss: 0.0114 - val_accuracy: 0.9897 - val_loss: 0.0498\n",
      "Epoch 21/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9970 - loss: 0.0102 - val_accuracy: 0.9888 - val_loss: 0.0523\n",
      "Epoch 22/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9969 - loss: 0.0086 - val_accuracy: 0.9898 - val_loss: 0.0554\n",
      "Epoch 23/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9965 - loss: 0.0099 - val_accuracy: 0.9893 - val_loss: 0.0543\n",
      "Epoch 24/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0082 - val_accuracy: 0.9898 - val_loss: 0.0601\n",
      "Epoch 25/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0080 - val_accuracy: 0.9905 - val_loss: 0.0550\n",
      "Epoch 26/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9971 - loss: 0.0082 - val_accuracy: 0.9906 - val_loss: 0.0546\n",
      "Epoch 27/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0073 - val_accuracy: 0.9912 - val_loss: 0.0567\n",
      "Epoch 28/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 0.9897 - val_loss: 0.0613\n",
      "Epoch 29/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9978 - loss: 0.0062 - val_accuracy: 0.9906 - val_loss: 0.0584\n",
      "Epoch 30/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9975 - loss: 0.0073 - val_accuracy: 0.9910 - val_loss: 0.0619\n",
      "Epoch 31/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0068 - val_accuracy: 0.9898 - val_loss: 0.0652\n",
      "Epoch 32/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - accuracy: 0.9972 - loss: 0.0077 - val_accuracy: 0.9902 - val_loss: 0.0657\n",
      "Epoch 33/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9979 - loss: 0.0058 - val_accuracy: 0.9908 - val_loss: 0.0632\n",
      "Epoch 34/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0060 - val_accuracy: 0.9900 - val_loss: 0.0678\n",
      "Epoch 35/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9979 - loss: 0.0057 - val_accuracy: 0.9910 - val_loss: 0.0596\n",
      "Epoch 36/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9980 - loss: 0.0059 - val_accuracy: 0.9898 - val_loss: 0.0743\n",
      "Epoch 37/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 0.9906 - val_loss: 0.0569\n",
      "Epoch 38/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9978 - loss: 0.0054 - val_accuracy: 0.9908 - val_loss: 0.0651\n",
      "Epoch 39/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9975 - loss: 0.0075 - val_accuracy: 0.9904 - val_loss: 0.0726\n",
      "Epoch 40/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0065 - val_accuracy: 0.9905 - val_loss: 0.0624\n",
      "Epoch 1/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8540 - loss: 0.4810 - val_accuracy: 0.9637 - val_loss: 0.1138\n",
      "Epoch 2/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9646 - loss: 0.1180 - val_accuracy: 0.9690 - val_loss: 0.0946\n",
      "Epoch 3/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9751 - loss: 0.0814 - val_accuracy: 0.9749 - val_loss: 0.0786\n",
      "Epoch 4/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9807 - loss: 0.0611 - val_accuracy: 0.9796 - val_loss: 0.0698\n",
      "Epoch 5/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.0489 - val_accuracy: 0.9801 - val_loss: 0.0644\n",
      "Epoch 6/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9866 - loss: 0.0411 - val_accuracy: 0.9816 - val_loss: 0.0673\n",
      "Epoch 7/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9879 - loss: 0.0390 - val_accuracy: 0.9780 - val_loss: 0.0794\n",
      "Epoch 8/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9878 - loss: 0.0357 - val_accuracy: 0.9818 - val_loss: 0.0649\n",
      "Epoch 9/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0256 - val_accuracy: 0.9821 - val_loss: 0.0741\n",
      "Epoch 10/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9907 - loss: 0.0276 - val_accuracy: 0.9816 - val_loss: 0.0691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.0250 - val_accuracy: 0.9822 - val_loss: 0.0708\n",
      "Epoch 12/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.0242 - val_accuracy: 0.9814 - val_loss: 0.0789\n",
      "Epoch 13/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.0222 - val_accuracy: 0.9843 - val_loss: 0.0677\n",
      "Epoch 14/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0217 - val_accuracy: 0.9837 - val_loss: 0.0724\n",
      "Epoch 15/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9929 - loss: 0.0198 - val_accuracy: 0.9815 - val_loss: 0.0923\n",
      "Epoch 16/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9932 - loss: 0.0208 - val_accuracy: 0.9819 - val_loss: 0.0851\n",
      "Epoch 17/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0154 - val_accuracy: 0.9831 - val_loss: 0.0893\n",
      "Epoch 18/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9940 - loss: 0.0171 - val_accuracy: 0.9831 - val_loss: 0.0824\n",
      "Epoch 19/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0171 - val_accuracy: 0.9827 - val_loss: 0.0820\n",
      "Epoch 20/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0148 - val_accuracy: 0.9826 - val_loss: 0.0881\n",
      "Epoch 21/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9950 - loss: 0.0155 - val_accuracy: 0.9844 - val_loss: 0.0797\n",
      "Epoch 22/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9960 - loss: 0.0126 - val_accuracy: 0.9847 - val_loss: 0.0823\n",
      "Epoch 23/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9952 - loss: 0.0151 - val_accuracy: 0.9837 - val_loss: 0.0865\n",
      "Epoch 24/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0163 - val_accuracy: 0.9830 - val_loss: 0.0873\n",
      "Epoch 25/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9959 - loss: 0.0132 - val_accuracy: 0.9834 - val_loss: 0.0996\n",
      "Epoch 26/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9947 - loss: 0.0194 - val_accuracy: 0.9841 - val_loss: 0.0873\n",
      "Epoch 27/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9972 - loss: 0.0091 - val_accuracy: 0.9815 - val_loss: 0.1027\n",
      "Epoch 28/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0154 - val_accuracy: 0.9834 - val_loss: 0.0932\n",
      "Epoch 29/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9962 - loss: 0.0118 - val_accuracy: 0.9840 - val_loss: 0.0824\n",
      "Epoch 30/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.0163 - val_accuracy: 0.9845 - val_loss: 0.0897\n",
      "Epoch 31/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0108 - val_accuracy: 0.9817 - val_loss: 0.1009\n",
      "Epoch 32/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9960 - loss: 0.0129 - val_accuracy: 0.9837 - val_loss: 0.0928\n",
      "Epoch 33/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0112 - val_accuracy: 0.9859 - val_loss: 0.0927\n",
      "Epoch 34/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 0.9825 - val_loss: 0.1073\n",
      "Epoch 35/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9965 - loss: 0.0116 - val_accuracy: 0.9838 - val_loss: 0.0956\n",
      "Epoch 36/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9959 - loss: 0.0152 - val_accuracy: 0.9845 - val_loss: 0.0959\n",
      "Epoch 37/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0110 - val_accuracy: 0.9826 - val_loss: 0.1118\n",
      "Epoch 38/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9959 - loss: 0.0158 - val_accuracy: 0.9847 - val_loss: 0.0949\n",
      "Epoch 39/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9971 - loss: 0.0091 - val_accuracy: 0.9853 - val_loss: 0.0915\n",
      "Epoch 40/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0089 - val_accuracy: 0.9856 - val_loss: 0.0920\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "batch_size = 86\n",
    "\n",
    "simple_conv_history = simple_conv_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val), verbose=1)\n",
    "dense_history = dense_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9869 - loss: 0.0672\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.1161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22409aedc40>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_conv_test_loss, simple_conv_test_acc = simple_conv_model.evaluate(x_test, y_test)\n",
    "dense_test_loss, dense_test_acc = dense_model.evaluate(x_test, y_test)\n",
    "\n",
    "plt.plot(dense_history.history[\"accuracy\"], \"b--\",label=\"dense training accuracy\")\n",
    "plt.plot(dense_history.history[\"val_accuracy\"], \"b-\",label=\"dense val accuracy\")\n",
    "plt.axhline(dense_test_acc, color=\"k\", linestyle=\":\", label=\"dense test accuracy\")\n",
    "plt.plot(simple_conv_history.history[\"accuracy\"], \"g--\",label=\"simple conv training accuracy\")\n",
    "plt.plot(simple_conv_history.history[\"val_accuracy\"], \"g-\",label=\"simple conv val accuracy\")\n",
    "plt.axhline(simple_conv_test_acc,color=\"k\", linestyle=\"--\", label=\"simple conv test accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0.94, 1.005)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
