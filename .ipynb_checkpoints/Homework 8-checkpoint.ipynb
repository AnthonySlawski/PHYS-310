{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIb7AW-J_Q0j"
   },
   "source": [
    "# Homework 8 - Hyperparameter optimization with keras tuner and CV with scikeras\n",
    "\n",
    "In this notebook, we use the photometric redshift problem to explore some hyperparameter optimization strategies for neural networks. We also take a look at CV with the scikeras wrapper.\n",
    "\n",
    "You might need to add keras tuner and scikeras to your tensorflow environment.\n",
    "\n",
    "*Modified from: Copyright: Viviana Acquaviva (2023). License: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wCi2a2GB_Q0m"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential #the model is built adding layers one after the other\n",
    "from keras.layers import Dense #fully connected layers: every output talks to every input\n",
    "from keras.layers import Dropout #for regularization\n",
    "\n",
    "# this is for the keras tuner\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6-Ir38f_Q05"
   },
   "source": [
    "Let us begin with the reduced (high-quality) data set we used for Bagging and Boosting methods. For reference, our best model achieved an outlier fraction of 4%.\n",
    "\n",
    "Read in 'sel_features.csv' and 'sel_target.csv' as X and y, respectively. You will need to shuffle X and y (use random_state=12) as we did in the previous notebook, and create a train/val/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.read_csv('sel_features.csv',sep='\\t')\n",
    "y=pd.read_csv('sel_target.csv',sep='\\t')\n",
    "\n",
    "X,y=shuffle(X,y,random_state=12)\n",
    "X_train, X_val, X_test = X[:3784], X[3784:5046], X[5046:]\n",
    "y_train, y_val, y_test = y[:3784], y[3784:5046], y[5046:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Hyperparameter search with keras tuner\n",
    "\n",
    "Keras tuner is a useful tool to explore different network configurations. Starting from the model we used in Lab 20, see if we can improve the choice of hyperparameters. There are many possibilities, but let's focus for now on the number and size of layers. We could start by varying the number of layers between 1-3 and the number of neurons from 50 to 200, in intervals of 50. The default learning rate is 0.001; we could check if 0.01 or 0.0001 might be better.\n",
    "\n",
    "Keras tuner is described in Ch. 8.4.3 in the textbook, you can follow along with the code examples from there.\n",
    "\n",
    "1. Define  function **build_model(hp)**. Since we found in the lab that mean absolute error gave us the best results, we could start with that one.\n",
    "2. Define a **RandomSearch** tuner. It is a good idea to first run *tf.keras.backend.clear_session()*\n",
    "3. Run the search. This is computationally very demanding and can take a long time. You don't need to let your computer work over night. You could start small, for instance ask for max_trials=20 only, executions_per_trial=1, only epochs=50 for training. Increase once you get a feeling for how long things take.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential() \n",
    "    for i in range(hp.Int('num_layers',1,4)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i), \n",
    "        min_value=50, max_value=200,step=50),activation='relu')) \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', \n",
    "    values=[1e-2, 1e-3, 1e-4])), loss='mae') \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XKTmAfeb_Q09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\antho\\anaconda3\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:73: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Reloading Tuner from hyperparameter_opt\\photometric_redshift\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    directory='hyperparameter_opt',\n",
    "    project_name='photometric_redshift'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XrqAgLjg_Q0-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search(x=X_train, y=y_train,\n",
    "             validation_data=(X_val, y_val),\n",
    "             epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FlfCn9m_Q0-"
   },
   "source": [
    "The \"results\\_summary(n)\" function gives us access to the n best models. It's useful to look at a few because often the differences are minimal, and a smaller model might be preferable! Run this with n=6 below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out some diagnostics:\n",
    "\n",
    "tuner.results_summary(5) let you look at the best 5 models\n",
    "\n",
    "tuner.get_best_hyperparameters()[0] picks the top model. \n",
    "\n",
    "model=tuner.hypermodel.build(best_hps) lets you define the model.\n",
    "\n",
    "model.build(input_shape=(None,6)) lets you build it\n",
    "\n",
    "Now fit this best model to the data, plot the test/validation loss curves, and compute the OLF and NMAD parameters. Were you able to get a better model than in lab 20?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seems like the same question twice, so I deleted the cells below and answered once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1685403266983,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "9AeqNold_Q0-",
    "outputId": "e0995af6-9513-4580-dfb6-2339255ab4df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in hyperparameter_opt\\photometric_redshift\n",
      "Showing 6 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 14 summary\n",
      "Hyperparameters:\n",
      "units_input: 100\n",
      "num_layers: 3\n",
      "units_0: 50\n",
      "dropout_0: 0.2\n",
      "learning_rate: 0.001\n",
      "units_1: 150\n",
      "dropout_1: 0.2\n",
      "units_2: 150\n",
      "dropout_2: 0.0\n",
      "Score: 0.09073787182569504\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units_input: 100\n",
      "num_layers: 3\n",
      "units_0: 100\n",
      "dropout_0: 0.1\n",
      "learning_rate: 0.0001\n",
      "units_1: 100\n",
      "dropout_1: 0.4\n",
      "units_2: 100\n",
      "dropout_2: 0.30000000000000004\n",
      "Score: 0.09458101540803909\n",
      "\n",
      "Trial 16 summary\n",
      "Hyperparameters:\n",
      "units_input: 200\n",
      "num_layers: 2\n",
      "units_0: 200\n",
      "dropout_0: 0.0\n",
      "learning_rate: 0.0001\n",
      "units_1: 200\n",
      "dropout_1: 0.2\n",
      "units_2: 150\n",
      "dropout_2: 0.0\n",
      "Score: 0.09660123288631439\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units_input: 150\n",
      "num_layers: 3\n",
      "units_0: 50\n",
      "dropout_0: 0.0\n",
      "learning_rate: 0.001\n",
      "units_1: 200\n",
      "dropout_1: 0.4\n",
      "units_2: 150\n",
      "dropout_2: 0.1\n",
      "Score: 0.10982884466648102\n",
      "\n",
      "Trial 15 summary\n",
      "Hyperparameters:\n",
      "units_input: 100\n",
      "num_layers: 2\n",
      "units_0: 150\n",
      "dropout_0: 0.30000000000000004\n",
      "learning_rate: 0.0001\n",
      "units_1: 50\n",
      "dropout_1: 0.2\n",
      "units_2: 100\n",
      "dropout_2: 0.30000000000000004\n",
      "Score: 0.11220045387744904\n",
      "\n",
      "Trial 11 summary\n",
      "Hyperparameters:\n",
      "units_input: 200\n",
      "num_layers: 1\n",
      "units_0: 50\n",
      "dropout_0: 0.30000000000000004\n",
      "learning_rate: 0.0001\n",
      "units_1: 150\n",
      "dropout_1: 0.2\n",
      "units_2: 50\n",
      "dropout_2: 0.2\n",
      "Score: 0.11922226846218109\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "OLF: zhelio    0.298969\n",
      "dtype: float64\n",
      "NMAD: 0.08232961277346343\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.results_summary(6)\n",
    "\n",
    "best_hps=tuner.get_best_hyperparameters()[0]\n",
    "model=tuner.hypermodel.build(best_hps)\n",
    "model.build(input_shape=(None,6))\n",
    "\n",
    "history=model.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=50,verbose=0)\n",
    "\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "print('OLF:',np.sum(np.abs(y_pred-y_test)>0.15)/len(y_test))\n",
    "print('NMAD:',1.48*np.median(np.abs(y_pred-y_test)/(1+np.abs(y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">22,650</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">151</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m350\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │         \u001b[38;5;34m7,650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │        \u001b[38;5;34m22,650\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m151\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">92,405</span> (360.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m92,405\u001b[0m (360.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,801</span> (120.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,801\u001b[0m (120.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,604</span> (240.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m61,604\u001b[0m (240.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMAD is better than lab 20 but OLF is worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: CV with scikeras wrapper\n",
    "\n",
    "In order to determine whether any improvement is significant, we should use cross validation. The scikeras wrapper is a convenient method that lets us use all the tools we previously learned from the scikit learn library with keras models. The textbook has a description in Chapter 8.4.4\n",
    "\n",
    "Set up three fold CV for the best model you found in the hyperparameter tuning. As usual, print the mean and standard deviation from the test and train scores.\n",
    "\n",
    "Compare it to our base model from lab 20, which had 2 layers with 100 neurons each and learning rate 0.001. Is your optimized model still better after CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `tf.saved_model.save()` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=C:\\Users\\antho\\AppData\\Local\\Temp\\tmp91x9rv9y.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m estimator\u001b[38;5;241m=\u001b[39mKerasRegressor(build_fn\u001b[38;5;241m=\u001b[39mmodel,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m pipeline\u001b[38;5;241m=\u001b[39mPipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m,StandardScaler()),(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m,estimator)])\n\u001b[1;32m----> 3\u001b[0m scores\u001b[38;5;241m=\u001b[39m\u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneg_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;66;03m# Sequentially call the tasks and yield the results.\u001b[39;00m\n\u001b[1;32m-> 1789\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\parallel.py:61\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m---> 61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:311\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    309\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m--> 311\u001b[0m         \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    312\u001b[0m         X,\n\u001b[0;32m    313\u001b[0m         y,\n\u001b[0;32m    314\u001b[0m         scorers,\n\u001b[0;32m    315\u001b[0m         train,\n\u001b[0;32m    316\u001b[0m         test,\n\u001b[0;32m    317\u001b[0m         verbose,\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    319\u001b[0m         fit_params,\n\u001b[0;32m    320\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m    321\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    322\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[0;32m    323\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:75\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct a new unfitted estimator with the same parameters.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03mClone does a deep copy of the model in an estimator\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03mfound in :ref:`randomness`.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_clone__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(estimator):\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_clone__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _clone_parametrized(estimator, safe\u001b[38;5;241m=\u001b[39msafe)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:268\u001b[0m, in \u001b[0;36mBaseEstimator.__sklearn_clone__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sklearn_clone__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_parametrized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:108\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m    106\u001b[0m new_object_params \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m new_object_params\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 108\u001b[0m     new_object_params[name] \u001b[38;5;241m=\u001b[39m \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m new_object \u001b[38;5;241m=\u001b[39m klass(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_object_params)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:76\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_clone__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(estimator):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39m__sklearn_clone__()\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_parametrized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:86\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: clone(v, safe\u001b[38;5;241m=\u001b[39msafe) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m estimator_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mset\u001b[39m, \u001b[38;5;28mfrozenset\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator_type([clone(e, safe\u001b[38;5;241m=\u001b[39msafe) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m estimator])\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, \u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m safe:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:86\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: clone(v, safe\u001b[38;5;241m=\u001b[39msafe) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m estimator_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mset\u001b[39m, \u001b[38;5;28mfrozenset\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator_type([\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m estimator])\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, \u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m safe:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:76\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_clone__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(estimator):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39m__sklearn_clone__()\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_parametrized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:86\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: clone(v, safe\u001b[38;5;241m=\u001b[39msafe) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m estimator_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mset\u001b[39m, \u001b[38;5;28mfrozenset\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator_type([clone(e, safe\u001b[38;5;241m=\u001b[39msafe) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m estimator])\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, \u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m safe:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:86\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: clone(v, safe\u001b[38;5;241m=\u001b[39msafe) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m estimator_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mset\u001b[39m, \u001b[38;5;28mfrozenset\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator_type([\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m estimator])\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, \u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m safe:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:75\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct a new unfitted estimator with the same parameters.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03mClone does a deep copy of the model in an estimator\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03mfound in :ref:`randomness`.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_clone__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(estimator):\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_clone__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _clone_parametrized(estimator, safe\u001b[38;5;241m=\u001b[39msafe)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:268\u001b[0m, in \u001b[0;36mBaseEstimator.__sklearn_clone__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sklearn_clone__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_parametrized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:108\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m    106\u001b[0m new_object_params \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m new_object_params\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 108\u001b[0m     new_object_params[name] \u001b[38;5;241m=\u001b[39m \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m new_object \u001b[38;5;241m=\u001b[39m klass(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_object_params)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:76\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_clone__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(estimator):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39m__sklearn_clone__()\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_parametrized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:89\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, \u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m safe:\n\u001b[1;32m---> 89\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scikeras\\_saving_utils.py:80\u001b[0m, in \u001b[0;36mdeepcopy_model\u001b[1;34m(model, memo)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeepcopy_model\u001b[39m(model: keras\u001b[38;5;241m.\u001b[39mModel, memo: Dict[Hashable, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel:\n\u001b[1;32m---> 80\u001b[0m     _, (model_bytes,) \u001b[38;5;241m=\u001b[39m \u001b[43mpack_keras_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     new_model \u001b[38;5;241m=\u001b[39m unpack_keras_model(model_bytes)\n\u001b[0;32m     82\u001b[0m     memo[model] \u001b[38;5;241m=\u001b[39m new_model\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scikeras\\_saving_utils.py:63\u001b[0m, in \u001b[0;36mpack_keras_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Support for Pythons's Pickle protocol.\"\"\"\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _get_temp_folder() \u001b[38;5;28;01mas\u001b[39;00m temp_dir:\n\u001b[1;32m---> 63\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     b \u001b[38;5;241m=\u001b[39m BytesIO()\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(fileobj\u001b[38;5;241m=\u001b[39mb, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m archive:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:106\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m     legacy_h5_format\u001b[38;5;241m.\u001b[39msave_model_to_hdf5(\n\u001b[0;32m    103\u001b[0m         model, filepath, overwrite, include_optimizer\n\u001b[0;32m    104\u001b[0m     )\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filepath extension for saving. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease add either a `.keras` extension for the native Keras \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat (recommended) or a `.h5` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `tf.saved_model.save()` if you want to export a SavedModel \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor use with TFLite/TFServing/etc. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `tf.saved_model.save()` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=C:\\Users\\antho\\AppData\\Local\\Temp\\tmp91x9rv9y."
     ]
    }
   ],
   "source": [
    "estimator=KerasRegressor(build_fn=model,epochs=50,batch_size=200,verbose=0)\n",
    "pipeline=Pipeline([('scale',StandardScaler()),('model',estimator)])\n",
    "scores=cross_validate(pipeline,X,y,cv=3,scoring='neg_mean_squared_error',return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I don't understand what is going wrong here, below I have put in the code from lab 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 235.7087 - val_loss: 951.7233\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 101.1325 - val_loss: 407.3230\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 59.9373 - val_loss: 330.8597\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 50.1311 - val_loss: 395.3822\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.7752 - val_loss: 461.4131\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 48.2986 - val_loss: 281.1872\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.1073 - val_loss: 382.7701\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45.0082 - val_loss: 624.7401\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 55.2067 - val_loss: 309.3068\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 45.8557 - val_loss: 188.5421\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 56.4360 - val_loss: 441.5895\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.6811 - val_loss: 501.9202\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 43.3977 - val_loss: 432.2274\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 38.5559 - val_loss: 425.0672\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.3434 - val_loss: 326.6798\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.7304 - val_loss: 492.9591\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 43.3471 - val_loss: 417.9994\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 44.7258 - val_loss: 369.6089\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.9941 - val_loss: 487.4440\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38.0510 - val_loss: 270.7328\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.8437 - val_loss: 526.0814\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 44.4615 - val_loss: 274.0353\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 43.6391 - val_loss: 624.3699\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 44.4422 - val_loss: 415.7293\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 35.8097 - val_loss: 396.6119\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.7065 - val_loss: 455.7721\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 38.1345 - val_loss: 438.9080\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.3277 - val_loss: 279.4467\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 64.4760 - val_loss: 690.8871\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 50.3278 - val_loss: 606.5851\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 44.3087 - val_loss: 457.3740\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.5636 - val_loss: 387.9976\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 35.1930 - val_loss: 345.2123\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 46.1308 - val_loss: 524.0458\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 35.9970 - val_loss: 425.6948\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.6881 - val_loss: 427.1128\n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.7898 - val_loss: 468.1349\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.3550 - val_loss: 435.5275\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 34.0762 - val_loss: 345.0164\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 35.5874 - val_loss: 377.0862\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.0412 - val_loss: 397.2523\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.9839 - val_loss: 513.1168\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 34.6261 - val_loss: 455.1796\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 35.6085 - val_loss: 368.8913\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.7532 - val_loss: 551.9681\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 37.5544 - val_loss: 587.8710\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 47.2239 - val_loss: 680.2105\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 52.0215 - val_loss: 645.4800\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 52.3146 - val_loss: 378.0971\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.2493 - val_loss: 623.9689\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.0018 - val_loss: 335.6400\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 36.4531 - val_loss: 343.6268\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 35.3240 - val_loss: 373.1692\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.2335 - val_loss: 709.8169\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.6920 - val_loss: 634.1283\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 45.6839 - val_loss: 283.5917\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 44.5321 - val_loss: 526.0986\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 34.8423 - val_loss: 346.2141\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.1263 - val_loss: 554.8717\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 38.8033 - val_loss: 355.0705\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.4012 - val_loss: 477.6914\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4843 - val_loss: 482.2156\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 34.2266 - val_loss: 462.2899\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 28.3006 - val_loss: 485.7917\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.0628 - val_loss: 482.6958\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.2367 - val_loss: 401.8411\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.7610 - val_loss: 372.9438\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.4582 - val_loss: 352.9896\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.7758 - val_loss: 594.4728\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.2374 - val_loss: 477.7884\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 62.7481 - val_loss: 134.1198\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 84.9144 - val_loss: 377.3444\n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 54.2761 - val_loss: 347.4508\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32.9630 - val_loss: 380.7249\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.9387 - val_loss: 400.5087\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 41.3798 - val_loss: 682.0695\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 51.4548 - val_loss: 249.3151\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 55.0485 - val_loss: 336.9091\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 48.4795 - val_loss: 523.8643\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 42.3395 - val_loss: 654.3927\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41.6637 - val_loss: 383.0108\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2373 - val_loss: 431.9645\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 29.0555 - val_loss: 399.1883\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.9586 - val_loss: 548.7071\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 32.1484 - val_loss: 386.2968\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.3137 - val_loss: 439.3808\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.5744 - val_loss: 407.5290\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29.2281 - val_loss: 522.4962\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.2398 - val_loss: 512.8024\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.7178 - val_loss: 418.6271\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.9268 - val_loss: 535.5526\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26.8155 - val_loss: 511.9687\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.3533 - val_loss: 373.3828\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.0354 - val_loss: 217.7674\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 61.2395 - val_loss: 674.7187\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 53.2850 - val_loss: 289.6378\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 63.4044 - val_loss: 136.2698\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 82.7262 - val_loss: 144.8238\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 87.4707 - val_loss: 397.5309\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 48.2775 - val_loss: 520.6110\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.4440\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Outlier Fraction: 0.09065901893188273\n",
      "Normalized Median Absolute Deviation: 0.42163485291239355\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model = keras.Sequential([\n",
    "    Dense(100, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_absolute_percentage_error')\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=300,\n",
    "                    validation_data=(X_val, y_val))\n",
    "mse=model.evaluate(X_test,y_test)\n",
    "predictions=model.predict(X_test)\n",
    "dz=np.abs(predictions.flatten()-y_test.values.flatten())\n",
    "outliers=np.where(y_test.values.flatten()>0.15,1,0)\n",
    "\n",
    "OLF=np.sum(dz[outliers==1]/(1+y_test.values.flatten()[outliers==1]))/len(y_test)\n",
    "\n",
    "NMAD=1.48*np.median(dz[outliers==0]/(1+y_test.values.flatten()[outliers==0]))\n",
    "\n",
    "print('Outlier Fraction:',OLF)\n",
    "print('Normalized Median Absolute Deviation:',NMAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
