{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIb7AW-J_Q0j"
   },
   "source": [
    "# Lab Notebook 20\n",
    "\n",
    "In this notebook, we use a fully connected neural network to solve a previously seen problem in regression: the photometric redshift problem  We also explore the effect of loss function and learning rate schedule. \n",
    "\n",
    "*Modified from: Copyright: Viviana Acquaviva (2023). License: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erin Bennett and Anthony Slawski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "wCi2a2GB_Q0m"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential #the model is built adding layers one after the other\n",
    "from keras.layers import Dense #fully connected layers: every output talks to every input\n",
    "from keras.layers import Dropout #for regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RELqQBID_Q0n"
   },
   "source": [
    "# Part 1: PhotoZ regression with a deep NN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLHnWtsJ_Q04"
   },
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6-Ir38f_Q05"
   },
   "source": [
    "Let us begin with the reduced (high-quality) data set we used for Bagging and Boosting methods. For reference, our best model achieved an outlier fraction of 4%.\n",
    "\n",
    "Read in 'sel_features.csv' and 'sel_target.csv' as X and y, respectively. You will need to shuffle X and y (use random_state=12) as we did in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "e8hFO3qM_Q05"
   },
   "outputs": [],
   "source": [
    "X=pd.read_csv('sel_features.csv',sep='\\t')\n",
    "y=pd.read_csv('sel_target.csv',sep='\\t')\n",
    "\n",
    "X,y=shuffle(X,y,random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the data into fifths; we would like to use a 60/20/20 split for training/validation/test. Define these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6307, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_apercor</th>\n",
       "      <th>g_apercor</th>\n",
       "      <th>r_apercor</th>\n",
       "      <th>i_apercor</th>\n",
       "      <th>z_apercor</th>\n",
       "      <th>y_apercor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>23.7774</td>\n",
       "      <td>23.4961</td>\n",
       "      <td>23.2445</td>\n",
       "      <td>22.9700</td>\n",
       "      <td>22.5860</td>\n",
       "      <td>22.4497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675</th>\n",
       "      <td>23.7430</td>\n",
       "      <td>23.3638</td>\n",
       "      <td>22.6674</td>\n",
       "      <td>21.7934</td>\n",
       "      <td>21.2195</td>\n",
       "      <td>21.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>24.1826</td>\n",
       "      <td>23.1667</td>\n",
       "      <td>22.6836</td>\n",
       "      <td>22.4811</td>\n",
       "      <td>22.3890</td>\n",
       "      <td>22.4926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>23.6480</td>\n",
       "      <td>23.2737</td>\n",
       "      <td>22.6016</td>\n",
       "      <td>22.3798</td>\n",
       "      <td>22.3236</td>\n",
       "      <td>22.3666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>24.0790</td>\n",
       "      <td>23.7875</td>\n",
       "      <td>23.3592</td>\n",
       "      <td>22.6754</td>\n",
       "      <td>22.4678</td>\n",
       "      <td>22.4220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      u_apercor  g_apercor  r_apercor  i_apercor  z_apercor  y_apercor\n",
       "4561    23.7774    23.4961    23.2445    22.9700    22.5860    22.4497\n",
       "3675    23.7430    23.3638    22.6674    21.7934    21.2195    21.0882\n",
       "3201    24.1826    23.1667    22.6836    22.4811    22.3890    22.4926\n",
       "780     23.6480    23.2737    22.6016    22.3798    22.3236    22.3666\n",
       "4205    24.0790    23.7875    23.3592    22.6754    22.4678    22.4220"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6307, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zhelio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>1.3944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675</th>\n",
       "      <td>0.9846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>0.1683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>0.4280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>0.8421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      zhelio\n",
       "4561  1.3944\n",
       "3675  0.9846\n",
       "3201  0.1683\n",
       "780   0.4280\n",
       "4205  0.8421"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "7JEkymDS_Q05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3784, 6), (1262, 6), (1261, 6), (3784, 1), (1262, 1), (1261, 1))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, X_test = X[:3784], X[3784:5046], X[5046:]\n",
    "y_train, y_val, y_test = y[:3784], y[3784:5046], y[5046:]\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aHqfJPv_Q05"
   },
   "source": [
    "We know that we need to scale our data! Do so below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1685403021297,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "lGcMKwtu_Q05",
    "outputId": "1bd10c4d-8302-408a-b51a-5e416d314aed"
   },
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_val=scaler.transform(X_val)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1zYQ1yg_Q06"
   },
   "source": [
    "## Step 2\n",
    "\n",
    "In a regression problem, we will choose a different activation for the output layer (linear), and an appropriate loss function (MSE). Our input layer has **six neurons** for this problem. For other parameters and the network structure, we can start with two relu-activated layers with **100 neurons** and go from there.\n",
    "\n",
    "1. Define your model using \"Sequential()\".\n",
    "2. Define your optimizer using the Adam optimizer from keras, and use the default learning rate of 0.001.\n",
    "3. Add an input layer and specify a size of 100 neurons (size=number of original features).\n",
    "4. Add one hidden layer and specify 100 neurons.\n",
    "5. Add an output layer with one neuron\n",
    "6. Finally, compile your model using MSE as the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(100, activation='relu',input_dim=X_train.shape[1]),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_pO8Jjl_Q06"
   },
   "source": [
    "To create your neural network, fit your model and use 100 epochs and batch size = 300:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17829,
     "status": "ok",
     "timestamp": 1685403046028,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "EpC58myL_Q06",
    "outputId": "dba21fd1-fc42-4061-d3f0-33095bc5a504",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.5603 - val_loss: 0.2461\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2209 - val_loss: 0.1581\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1321 - val_loss: 0.0992\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0751 - val_loss: 0.0679\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0503 - val_loss: 0.0581\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0412 - val_loss: 0.0555\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0449 - val_loss: 0.0550\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0464 - val_loss: 0.0548\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0422 - val_loss: 0.0541\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0405 - val_loss: 0.0539\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0380 - val_loss: 0.0537\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0469 - val_loss: 0.0527\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0455 - val_loss: 0.0523\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0442 - val_loss: 0.0521\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0366 - val_loss: 0.0522\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0382 - val_loss: 0.0519\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0390 - val_loss: 0.0522\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0362 - val_loss: 0.0512\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0405 - val_loss: 0.0514\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0398 - val_loss: 0.0501\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0382 - val_loss: 0.0509\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0334 - val_loss: 0.0501\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0347 - val_loss: 0.0501\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0435 - val_loss: 0.0505\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0457 - val_loss: 0.0495\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0396 - val_loss: 0.0499\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0371 - val_loss: 0.0491\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0338 - val_loss: 0.0501\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0344 - val_loss: 0.0495\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0371 - val_loss: 0.0487\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0387 - val_loss: 0.0488\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0326 - val_loss: 0.0494\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0273 - val_loss: 0.0474\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0379 - val_loss: 0.0481\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0321 - val_loss: 0.0481\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.0483\n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0315 - val_loss: 0.0476\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0344 - val_loss: 0.0480\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0335 - val_loss: 0.0476\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0373 - val_loss: 0.0469\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0315 - val_loss: 0.0465\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0479\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0370 - val_loss: 0.0469\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.0469\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0276 - val_loss: 0.0460\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0347 - val_loss: 0.0463\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0267 - val_loss: 0.0462\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0261 - val_loss: 0.0468\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.0462\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0284 - val_loss: 0.0460\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0302 - val_loss: 0.0455\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0278 - val_loss: 0.0456\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0449\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.0459\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0276 - val_loss: 0.0460\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0337 - val_loss: 0.0447\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0283 - val_loss: 0.0458\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0262 - val_loss: 0.0456\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0295 - val_loss: 0.0444\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0271 - val_loss: 0.0456\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0449\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0348 - val_loss: 0.0450\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0331 - val_loss: 0.0444\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0258 - val_loss: 0.0446\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0224 - val_loss: 0.0443\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0291 - val_loss: 0.0450\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0250 - val_loss: 0.0451\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0240 - val_loss: 0.0457\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0283 - val_loss: 0.0450\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0258 - val_loss: 0.0458\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0315 - val_loss: 0.0447\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0262 - val_loss: 0.0438\n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0298 - val_loss: 0.0450\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0257 - val_loss: 0.0442\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0262 - val_loss: 0.0440\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0224 - val_loss: 0.0450\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0271 - val_loss: 0.0435\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0447\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0275 - val_loss: 0.0446\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0303 - val_loss: 0.0436\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0306 - val_loss: 0.0442\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0225 - val_loss: 0.0438\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0224 - val_loss: 0.0440\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0240 - val_loss: 0.0458\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0274 - val_loss: 0.0430\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0292 - val_loss: 0.0441\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0209 - val_loss: 0.0450\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0236 - val_loss: 0.0445\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0443\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0442\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0211 - val_loss: 0.0436\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0211 - val_loss: 0.0442\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0240 - val_loss: 0.0440\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0229 - val_loss: 0.0435\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0208 - val_loss: 0.0434\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0442\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0434\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0224 - val_loss: 0.0439\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0195 - val_loss: 0.0435\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0432\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=300,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use \"model.evaluate\" to find the MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1685403046029,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "R9F0vSIG_Q07",
    "outputId": "3acbecba-51eb-471b-ba8d-7b9f98ea56d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 0.0320\n",
      "Mean Squared Error: 0.025199096649885178\n"
     ]
    }
   ],
   "source": [
    "mse=model.evaluate(X_test,y_test)\n",
    "print('Mean Squared Error:',mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6o1--T2H_Q07"
   },
   "source": [
    "## Step 3\n",
    "\n",
    "As in the previous lab, we can plot the loss as a function of epoch from the train and validation data sets. Here the loss is of course the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 982
    },
    "executionInfo": {
     "elapsed": 938,
     "status": "ok",
     "timestamp": 1685403046962,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "igJTaSwy_Q07",
    "outputId": "0375ff29-c1c5-4e19-850c-f88c516407cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22419c0c8b0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Npn26F0Uo0X3"
   },
   "source": [
    "As always with regression problems, it is helpful to plot the predictions against the true values. Plot estimated redshift versus true redshift in a scatter plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3269,
     "status": "ok",
     "timestamp": 1685403054362,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "4j5LEBae_Q07",
    "outputId": "19fe2018-555e-4779-96a8-4ede8522a99f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions=model.predict(X_test)\n",
    "\n",
    "plt.scatter(y_test,predictions)\n",
    "plt.title('Estimated Redshift vs True Redshift')\n",
    "plt.xlabel('True Redshift')\n",
    "plt.ylabel('Estimated Redshift')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AISbbpfKo-nn"
   },
   "source": [
    "## Step 4\n",
    "\n",
    "We didn't do cross validation, so we can only generate predictions on our single test fold in order to derive the other metrics we are interested in.\n",
    "\n",
    "First, calculate the Outlier Fraction (OLF):\n",
    "\n",
    "$\\mathrm{OLF} = \\mathrm{num}\\left ( \\frac{|\\Delta z|}{1+z_{\\mathrm{true}}} > 0.15 = \\mathrm{true} \\right)/N$\n",
    "\n",
    "*The numerator is the number of instances where $\\frac{|\\Delta z|}{1+z_{\\mathrm{true}}}>0.15$ is true. $N$ is the length of $y_{\\mathrm{test}}$.*\n",
    "\n",
    "We can also calculate the Normalized Median Absolute Deviation (NMAD):\n",
    "\n",
    "$\\sigma_{\\mathrm{NMAD}}=1.48 \\times \\mathrm{median}\\left ( \\frac{|\\Delta z|}{1+z_{\\mathrm{true}}}\\right )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1685403054567,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "jB8PgXsG_Q08",
    "outputId": "d0001149-d329-4b15-d9de-8fdda7ad1926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Fraction: 0.03954251389489335\n",
      "Normalized Median Absolute Deviation: 0.24009333061117938\n"
     ]
    }
   ],
   "source": [
    "dz=np.abs(predictions.flatten()-y_test.values.flatten())\n",
    "outliers=np.where(y_test.values.flatten()>0.15,1,0)\n",
    "\n",
    "OLF=np.sum(dz[outliers==1]/(1+y_test.values.flatten()[outliers==1]))/len(y_test)\n",
    "\n",
    "NMAD=1.48*np.median(dz[outliers==0]/(1+y_test.values.flatten()[outliers==0]))\n",
    "\n",
    "print('Outlier Fraction:',OLF)\n",
    "print('Normalized Median Absolute Deviation:',NMAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Effect of loss function\n",
    "\n",
    "So far, we have used the MSE loss in our training, but this choice is not unique. Would using the MAE or MAPE loss functions give better results for the OLF and NMAD parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.5317 - val_loss: 0.3553\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3330 - val_loss: 0.2709\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2455 - val_loss: 0.1946\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1810 - val_loss: 0.1394\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1309 - val_loss: 0.1217\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1216 - val_loss: 0.1133\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1132 - val_loss: 0.1076\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1114 - val_loss: 0.1038\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1048 - val_loss: 0.1037\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0993 - val_loss: 0.0989\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0942 - val_loss: 0.0968\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0935 - val_loss: 0.0934\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0918 - val_loss: 0.0936\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0901 - val_loss: 0.0900\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0923 - val_loss: 0.0878\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0872 - val_loss: 0.0881\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0876 - val_loss: 0.0882\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0876 - val_loss: 0.0858\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0864 - val_loss: 0.0853\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0867 - val_loss: 0.0850\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0825 - val_loss: 0.0829\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0828 - val_loss: 0.0837\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0828 - val_loss: 0.0818\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0820 - val_loss: 0.0808\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0844 - val_loss: 0.0838\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0828 - val_loss: 0.0808\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0869 - val_loss: 0.0824\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0826 - val_loss: 0.0783\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0792 - val_loss: 0.0781\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0776 - val_loss: 0.0799\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0759 - val_loss: 0.0774\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0803 - val_loss: 0.0835\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0827 - val_loss: 0.0787\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0801 - val_loss: 0.0779\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0773 - val_loss: 0.0782\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0838 - val_loss: 0.0755\n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0789 - val_loss: 0.0754\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0803 - val_loss: 0.0755\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0790 - val_loss: 0.0775\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0784 - val_loss: 0.0747\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0754 - val_loss: 0.0797\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0761 - val_loss: 0.0753\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0762 - val_loss: 0.0789\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0750 - val_loss: 0.0748\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0723 - val_loss: 0.0749\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0797 - val_loss: 0.0743\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0824 - val_loss: 0.0743\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0751 - val_loss: 0.0757\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0733 - val_loss: 0.0761\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0768 - val_loss: 0.0797\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0797 - val_loss: 0.0732\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0739 - val_loss: 0.0719\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0717 - val_loss: 0.0728\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0745 - val_loss: 0.0739\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0802 - val_loss: 0.0709\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0782 - val_loss: 0.0723\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0754 - val_loss: 0.0704\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0751 - val_loss: 0.0706\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0749 - val_loss: 0.0702\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0731 - val_loss: 0.0710\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0704 - val_loss: 0.0695\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0694 - val_loss: 0.0699\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0716 - val_loss: 0.0701\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0673 - val_loss: 0.0706\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0692 - val_loss: 0.0696\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0721 - val_loss: 0.0702\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0708 - val_loss: 0.0683\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0667 - val_loss: 0.0692\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0664 - val_loss: 0.0683\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0692 - val_loss: 0.0680\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0716 - val_loss: 0.0678\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0657 - val_loss: 0.0680\n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0660 - val_loss: 0.0677\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0681 - val_loss: 0.0666\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0636 - val_loss: 0.0666\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0655 - val_loss: 0.0663\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0660 - val_loss: 0.0663\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0693 - val_loss: 0.0661\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0698 - val_loss: 0.0679\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0676 - val_loss: 0.0650\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0664 - val_loss: 0.0660\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0657 - val_loss: 0.0663\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0653 - val_loss: 0.0645\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0634 - val_loss: 0.0652\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0639 - val_loss: 0.0644\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0632 - val_loss: 0.0657\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0628 - val_loss: 0.0655\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0623 - val_loss: 0.0673\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0662 - val_loss: 0.0713\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0684 - val_loss: 0.0693\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0669 - val_loss: 0.0664\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0713 - val_loss: 0.0637\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0674 - val_loss: 0.0626\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0597 - val_loss: 0.0655\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0618 - val_loss: 0.0649\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0619 - val_loss: 0.0660\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0640 - val_loss: 0.0621\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0672 - val_loss: 0.0616\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0606 - val_loss: 0.0630\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0585 - val_loss: 0.0629\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.0646\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Outlier Fraction (OLF): 0.029869130638473566\n",
      "Normalized Median Absolute Deviation: 0.11785846570986856\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(100, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_absolute_error')\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=300,\n",
    "                    validation_data=(X_val, y_val))\n",
    "mse=model.evaluate(X_test,y_test)\n",
    "predictions=model.predict(X_test)\n",
    "dz=np.abs(predictions.flatten()-y_test.values.flatten())\n",
    "outliers=np.where(y_test.values.flatten()>0.15,1,0)\n",
    "\n",
    "OLF=np.sum(dz[outliers==1]/(1+y_test.values.flatten()[outliers==1]))/len(y_test)\n",
    "\n",
    "NMAD=1.48*np.median(dz[outliers==0]/(1+y_test.values.flatten()[outliers==0]))\n",
    "\n",
    "print('Outlier Fraction (OLF):',OLF)\n",
    "print('Normalized Median Absolute Deviation:',NMAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 69.9803 - val_loss: 531.5189\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.8677 - val_loss: 463.0758\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 35.8970 - val_loss: 460.9753\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24.1942 - val_loss: 483.3430\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.4708 - val_loss: 481.4482\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.2352 - val_loss: 467.6776\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.8420 - val_loss: 470.6018\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.1062 - val_loss: 452.4502\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.6002 - val_loss: 469.2986\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.2498 - val_loss: 492.0035\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.7553 - val_loss: 493.1736\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.0949 - val_loss: 477.1015\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.1835 - val_loss: 475.0949\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.8174 - val_loss: 489.8116\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.3918 - val_loss: 472.3070\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.9970 - val_loss: 470.6703\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.8402 - val_loss: 488.5715\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.4360 - val_loss: 496.7576\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.6895 - val_loss: 459.5031\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.2572 - val_loss: 485.2576\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.3251 - val_loss: 471.8500\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.7296 - val_loss: 497.4356\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.9805 - val_loss: 494.6486\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.5513 - val_loss: 497.7452\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.1900 - val_loss: 509.3753\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.7499 - val_loss: 499.3004\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.9182 - val_loss: 506.0121\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.6502 - val_loss: 521.5665\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.5566 - val_loss: 519.6657\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.8148 - val_loss: 507.3016\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.6009 - val_loss: 497.7833\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.4811 - val_loss: 479.9874\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.0738 - val_loss: 494.7236\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.7439 - val_loss: 514.5071\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.1993 - val_loss: 506.7028\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3108 - val_loss: 504.6549\n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.6060 - val_loss: 513.2832\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.8011 - val_loss: 524.8237\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2254 - val_loss: 524.2330\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.5775 - val_loss: 528.9224\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3173 - val_loss: 538.3546\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.8458 - val_loss: 526.4347\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.9670 - val_loss: 544.5145\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.3844 - val_loss: 530.7026\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.6348 - val_loss: 528.7263\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.1510 - val_loss: 534.9683\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2643 - val_loss: 517.0321\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7568 - val_loss: 535.3434\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.1602 - val_loss: 522.4210\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.8104 - val_loss: 519.0080\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2940 - val_loss: 517.4413\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.8429 - val_loss: 528.1097\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.8802 - val_loss: 522.4369\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.6322 - val_loss: 520.7933\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7834 - val_loss: 543.4620\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0915 - val_loss: 534.7511\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.7004 - val_loss: 541.4969\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.4487 - val_loss: 553.2942\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0229 - val_loss: 561.8250\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.1973 - val_loss: 556.8032\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.4516 - val_loss: 563.4818\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.6156 - val_loss: 536.5652\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5379 - val_loss: 539.3442\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5510 - val_loss: 534.9749\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1119 - val_loss: 560.4349\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5483 - val_loss: 545.2268\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.6500 - val_loss: 547.6217\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1981 - val_loss: 549.1443\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.1230 - val_loss: 541.0747\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.1484 - val_loss: 535.8433\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6044 - val_loss: 526.2236\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.4632 - val_loss: 553.9990\n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.1790 - val_loss: 552.7339\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.1949 - val_loss: 538.6310\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.2613 - val_loss: 538.0098\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2216 - val_loss: 544.4111\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.5659 - val_loss: 594.0215\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.4449 - val_loss: 543.8141\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.4621 - val_loss: 562.0219\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3860 - val_loss: 541.5809\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6715 - val_loss: 522.7265\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1436 - val_loss: 552.3893\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0509 - val_loss: 544.7473\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2158 - val_loss: 556.8631\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.8153 - val_loss: 542.4384\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2670 - val_loss: 536.9922\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2873 - val_loss: 528.6790\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.7267 - val_loss: 541.9886\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.5245 - val_loss: 537.6390\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2981 - val_loss: 534.3123\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0574 - val_loss: 538.2880\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.1125 - val_loss: 538.4843\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5180 - val_loss: 542.5656\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6302 - val_loss: 515.4832\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7267 - val_loss: 550.3041\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.6918 - val_loss: 534.0624\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1477 - val_loss: 538.0068\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6991 - val_loss: 544.3795\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0275 - val_loss: 539.7706\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.4041 - val_loss: 543.9605\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.6044  \n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Outlier Fraction: 0.03296044424286397\n",
      "Normalized Median Absolute Deviation: 0.060834896352070164\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(100, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_absolute_percentage_error')\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=300,\n",
    "                    validation_data=(X_val, y_val))\n",
    "mse=model.evaluate(X_test,y_test)\n",
    "predictions=model.predict(X_test)\n",
    "dz=np.abs(predictions.flatten()-y_test.values.flatten())\n",
    "outliers=np.where(y_test.values.flatten()>0.15,1,0)\n",
    "\n",
    "OLF=np.sum(dz[outliers==1]/(1+y_test.values.flatten()[outliers==1]))/len(y_test)\n",
    "\n",
    "NMAD=1.48*np.median(dz[outliers==0]/(1+y_test.values.flatten()[outliers==0]))\n",
    "\n",
    "print('Outlier Fraction:',OLF)\n",
    "print('Normalized Median Absolute Deviation:',NMAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE loss gives the better overall results for the OLF and NMAD parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Effect of learning rate schedules\n",
    "\n",
    "When training a neural network, we can tune the performance by optimizing a large set of hyperparameters. Last time, we looked at the choice of optimizer and regularization. Another important parameter is the learning rate. A learning rate that is set too small will slow down the training, as we update the weights of the network in tiny steps. On the other hand, if the learning rate is set too high, the training can diverge. Usually we want to start with a large learning rate to make fast progress and then slow down the training close to the optimum. This can be achieved by using learning rate schedules, which we will investigate in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Time based-decay\n",
    "\n",
    "First we can try a time-based decay:\n",
    "$$\\eta(t)=\\eta_0/(1+t⋅\\eta_0/n_{epochs})$$\n",
    "\n",
    "where $\\eta_0$ is the initial learning rate, $t$ the iteration number (epoch) and $n_{epochs}$ the total number of epochs. \n",
    "\n",
    "Write a function (i.e the learning schedule) that implements this learning schedule. The function takes an epoch index (integer, indexed from 0) and current learning rate (float) as inputs and returns a new learning rate as output (float). In our case, the current learning rate is not actually used in the function, but this format is expected when we use it in keras later. Set the initial learning rate to 0.001 and the number of epochs to 100. Make a plot of the learning rate as a function of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_based_decay(epoch, cur_lr):\n",
    "    init_lr = 0.001\n",
    "    epochs = 100\n",
    "    decay_rate = init_lr / epochs\n",
    "    new_lr = init_lr / (1 + epoch * decay_rate)\n",
    "    return new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Learning Rate')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs=range(100)\n",
    "learning_rates=[time_based_decay(epoch, 0) for epoch in epochs]\n",
    "plt.plot(epochs,learning_rates)\n",
    "plt.title('Learning Rate Schedule: Time-based Decay')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with this new learning rate schedule, and save the history. Remember to rebuild the model to re-initialize all weights and biases. To use the learning rate schedule, add **callbacks=[keras.callbacks.LearningRateScheduler(my_function, verbose=1)]** to model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.4148 - val_loss: 0.2563 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0009999900000999989.\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2079 - val_loss: 0.1362 - learning_rate: 9.9999e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.000999980000399992.\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1078 - val_loss: 0.0779 - learning_rate: 9.9998e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.000999970000899973.\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0591 - val_loss: 0.0614 - learning_rate: 9.9997e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.000999960001599936.\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0481 - val_loss: 0.0559 - learning_rate: 9.9996e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.000999950002499875.\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0418 - val_loss: 0.0549 - learning_rate: 9.9995e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.000999940003599784.\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0472 - val_loss: 0.0549 - learning_rate: 9.9994e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.000999930004899657.\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0457 - val_loss: 0.0534 - learning_rate: 9.9993e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.000999920006399488.\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0445 - val_loss: 0.0527 - learning_rate: 9.9992e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0009999100080992712.\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0435 - val_loss: 0.0522 - learning_rate: 9.9991e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.000999900009999.\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0397 - val_loss: 0.0520 - learning_rate: 9.9990e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.000999890012098669.\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0429 - val_loss: 0.0511 - learning_rate: 9.9989e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0009998800143982724.\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0422 - val_loss: 0.0508 - learning_rate: 9.9988e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0009998700168978034.\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0395 - val_loss: 0.0514 - learning_rate: 9.9987e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0009998600195972563.\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0358 - val_loss: 0.0505 - learning_rate: 9.9986e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0009998500224966255.\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0333 - val_loss: 0.0499 - learning_rate: 9.9985e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0009998400255959048.\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0341 - val_loss: 0.0498 - learning_rate: 9.9984e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0009998300288950879.\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0499 - learning_rate: 9.9983e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.000999820032394169.\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0353 - val_loss: 0.0496 - learning_rate: 9.9982e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0009998100360931424.\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0331 - val_loss: 0.0494 - learning_rate: 9.9981e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0009998000399920016.\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.0492 - learning_rate: 9.9980e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000999790044090741.\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0485 - learning_rate: 9.9979e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0009997800483893542.\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0480 - learning_rate: 9.9978e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.000999770052887836.\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0302 - val_loss: 0.0483 - learning_rate: 9.9977e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0009997600575861792.\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0327 - val_loss: 0.0490 - learning_rate: 9.9976e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0009997500624843788.\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0324 - val_loss: 0.0481 - learning_rate: 9.9975e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0009997400675824286.\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0480 - learning_rate: 9.9974e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0009997300728803223.\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0480 - learning_rate: 9.9973e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0009997200783780542.\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0344 - val_loss: 0.0480 - learning_rate: 9.9972e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0009997100840756182.\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0287 - val_loss: 0.0477 - learning_rate: 9.9971e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.000999700089973008.\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0321 - val_loss: 0.0477 - learning_rate: 9.9970e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0009996900960702183.\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0469 - learning_rate: 9.9969e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0009996801023672425.\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0406 - val_loss: 0.0476 - learning_rate: 9.9968e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.000999670108864075.\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.0470 - learning_rate: 9.9967e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0009996601155607093.\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0309 - val_loss: 0.0472 - learning_rate: 9.9966e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0009996501224571398.\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0471 - learning_rate: 9.9965e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0009996401295533609.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0469 - learning_rate: 9.9964e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0009996301368493659.\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0479 - learning_rate: 9.9963e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0009996201443451488.\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0349 - val_loss: 0.0487 - learning_rate: 9.9962e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0009996101520407042.\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0471 - learning_rate: 9.9961e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0009996001599360256.\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0338 - val_loss: 0.0469 - learning_rate: 9.9960e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.0009995901680311073.\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0309 - val_loss: 0.0467 - learning_rate: 9.9959e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0009995801763259431.\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0471 - learning_rate: 9.9958e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0009995701848205273.\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.0461 - learning_rate: 9.9957e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0009995601935148535.\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.0463 - learning_rate: 9.9956e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0009995502024089159.\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0474 - learning_rate: 9.9955e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.000999540211502709.\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0274 - val_loss: 0.0459 - learning_rate: 9.9954e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.000999530220796226.\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0316 - val_loss: 0.0461 - learning_rate: 9.9953e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.000999520230289461.\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0314 - val_loss: 0.0463 - learning_rate: 9.9952e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.0009995102399824086.\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0269 - val_loss: 0.0456 - learning_rate: 9.9951e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.0009995002498750627.\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0325 - val_loss: 0.0456 - learning_rate: 9.9950e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.0009994902599674165.\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0461 - learning_rate: 9.9949e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.000999480270259465.\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0283 - val_loss: 0.0467 - learning_rate: 9.9948e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.000999470280751202.\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0459 - learning_rate: 9.9947e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.000999460291442621.\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0268 - val_loss: 0.0470 - learning_rate: 9.9946e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.0009994503023337165.\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0454 - learning_rate: 9.9945e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.0009994403134244824.\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0228 - val_loss: 0.0469 - learning_rate: 9.9944e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0009994303247149127.\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0462 - learning_rate: 9.9943e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.0009994203362050011.\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0242 - val_loss: 0.0474 - learning_rate: 9.9942e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.000999410347894742.\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0252 - val_loss: 0.0457 - learning_rate: 9.9941e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.0009994003597841297.\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0279 - val_loss: 0.0457 - learning_rate: 9.9940e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.0009993903718731574.\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0244 - val_loss: 0.0452 - learning_rate: 9.9939e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.0009993803841618196.\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0447 - learning_rate: 9.9938e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.0009993703966501106.\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0446 - learning_rate: 9.9937e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.0009993604093380237.\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0455 - learning_rate: 9.9936e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.0009993504222255533.\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0455 - learning_rate: 9.9935e-04\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.0009993404353126935.\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0303 - val_loss: 0.0447 - learning_rate: 9.9934e-04\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.0009993304485994385.\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0443 - learning_rate: 9.9933e-04\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.0009993204620857817.\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0222 - val_loss: 0.0462 - learning_rate: 9.9932e-04\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.0009993104757717174.\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0454 - learning_rate: 9.9931e-04\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.00099930048965724.\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0245 - val_loss: 0.0452 - learning_rate: 9.9930e-04\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.0009992905037423429.\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0258 - val_loss: 0.0454 - learning_rate: 9.9929e-04\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.0009992805180270205.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0262 - val_loss: 0.0489 - learning_rate: 9.9928e-04\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.0009992705325112669.\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0313 - val_loss: 0.0455 - learning_rate: 9.9927e-04\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.0009992605471950758.\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0231 - val_loss: 0.0448 - learning_rate: 9.9926e-04\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.0009992505620784412.\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0217 - val_loss: 0.0452 - learning_rate: 9.9925e-04\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.0009992405771613573.\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0270 - val_loss: 0.0452 - learning_rate: 9.9924e-04\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.0009992305924438184.\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0453 - learning_rate: 9.9923e-04\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.0009992206079258179.\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0461 - learning_rate: 9.9922e-04\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.0009992106236073502.\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0268 - val_loss: 0.0454 - learning_rate: 9.9921e-04\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.0009992006394884093.\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0226 - val_loss: 0.0451 - learning_rate: 9.9920e-04\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.0009991906555689891.\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0254 - val_loss: 0.0464 - learning_rate: 9.9919e-04\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.0009991806718490836.\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0466 - learning_rate: 9.9918e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.0009991706883286872.\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0263 - val_loss: 0.0457 - learning_rate: 9.9917e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.0009991607050077935.\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0255 - val_loss: 0.0462 - learning_rate: 9.9916e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.0009991507218863967.\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0258 - val_loss: 0.0452 - learning_rate: 9.9915e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.0009991407389644904.\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0274 - val_loss: 0.0451 - learning_rate: 9.9914e-04\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.0009991307562420696.\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0449 - learning_rate: 9.9913e-04\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.0009991207737191272.\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0210 - val_loss: 0.0452 - learning_rate: 9.9912e-04\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.0009991107913956579.\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0210 - val_loss: 0.0457 - learning_rate: 9.9911e-04\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.0009991008092716557.\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0457 - learning_rate: 9.9910e-04\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.0009990908273471142.\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0205 - val_loss: 0.0456 - learning_rate: 9.9909e-04\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.0009990808456220278.\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0257 - val_loss: 0.0450 - learning_rate: 9.9908e-04\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 0.0009990708640963903.\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0254 - val_loss: 0.0461 - learning_rate: 9.9907e-04\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.000999060882770196.\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0225 - val_loss: 0.0461 - learning_rate: 9.9906e-04\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.0009990509016434388.\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0212 - val_loss: 0.0458 - learning_rate: 9.9905e-04\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.0009990409207161124.\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0185 - val_loss: 0.0441 - learning_rate: 9.9904e-04\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.0009990309399882115.\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0217 - val_loss: 0.0457 - learning_rate: 9.9903e-04\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.0009990209594597295.\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0244 - val_loss: 0.0459 - learning_rate: 9.9902e-04\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.0009990109791306607.\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0217 - val_loss: 0.0456 - learning_rate: 9.9901e-04\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(100, activation='relu',input_dim=X_train.shape[1]),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "lr_schedule = keras.callbacks.LearningRateScheduler(time_based_decay, verbose=1)\n",
    "\n",
    "history_t = model.fit(X_train,\n",
    "                                y_train, epochs=100, \n",
    "                                batch_size=300, \n",
    "                                validation_data=(X_val, y_val), \n",
    "                                callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exponential decay\n",
    "\n",
    "Repeat Part 3 Step 1 for a different learning schedule that uses exponential decay,\n",
    "\n",
    "$$ \\eta(t)=\\eta_0⋅e^{−k⋅t},$$\n",
    "\n",
    "where $k$ is the decay rate. We can try k=0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(epoch, lr):\n",
    "    initial_lr = 0.001\n",
    "    k = 0.01\n",
    "    new_lr = initial_lr * np.exp(-k * epoch)\n",
    "    return new_lr\n",
    "\n",
    "epochs=np.arange(100)\n",
    "lr=0.001\n",
    "learning_rates = [exponential_decay(epoch, lr) for epoch in epochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, learning_rates)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Exponential Decay Learning Rate Schedule')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.4306 - val_loss: 0.2464 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.000990049833749168.\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1914 - val_loss: 0.1202 - learning_rate: 9.9005e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0009801986733067552.\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0921 - val_loss: 0.0782 - learning_rate: 9.8020e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0009704455335485082.\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0697 - val_loss: 0.0607 - learning_rate: 9.7045e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0009607894391523232.\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0441 - val_loss: 0.0562 - learning_rate: 9.6079e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.000951229424500714.\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0391 - val_loss: 0.0563 - learning_rate: 9.5123e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0009417645335842487.\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0437 - val_loss: 0.0548 - learning_rate: 9.4176e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0009323938199059483.\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0426 - val_loss: 0.0543 - learning_rate: 9.3239e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0009231163463866358.\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0390 - val_loss: 0.0533 - learning_rate: 9.2312e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0009139311852712283.\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0490 - val_loss: 0.0530 - learning_rate: 9.1393e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009048374180359595.\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0487 - val_loss: 0.0525 - learning_rate: 9.0484e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0008958341352965282.\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0391 - val_loss: 0.0513 - learning_rate: 8.9583e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008869204367171575.\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0487 - val_loss: 0.0514 - learning_rate: 8.8692e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008780954309205613.\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0325 - val_loss: 0.0508 - learning_rate: 8.7810e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0008693582353988059.\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0358 - val_loss: 0.0507 - learning_rate: 8.6936e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0008607079764250578.\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0379 - val_loss: 0.0507 - learning_rate: 8.6071e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0008521437889662113.\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0334 - val_loss: 0.0505 - learning_rate: 8.5214e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0008436648165963838.\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0465 - val_loss: 0.0511 - learning_rate: 8.4366e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.000835270211411272.\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0388 - val_loss: 0.0506 - learning_rate: 8.3527e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0008269591339433623.\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0399 - val_loss: 0.0496 - learning_rate: 8.2696e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0008187307530779819.\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0343 - val_loss: 0.0495 - learning_rate: 8.1873e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0008105842459701871.\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0346 - val_loss: 0.0501 - learning_rate: 8.1058e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0008025187979624785.\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0380 - val_loss: 0.0500 - learning_rate: 8.0252e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.000794533602503334.\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0490 - learning_rate: 7.9453e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0007866278610665535.\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0401 - val_loss: 0.0487 - learning_rate: 7.8663e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0007788007830714049.\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0328 - val_loss: 0.0487 - learning_rate: 7.7880e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0007710515858035663.\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0491 - learning_rate: 7.7105e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0007633794943368531.\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0288 - val_loss: 0.0493 - learning_rate: 7.6338e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0007557837414557255.\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0356 - val_loss: 0.0483 - learning_rate: 7.5578e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0007482635675785653.\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0320 - val_loss: 0.0481 - learning_rate: 7.4826e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0007408182206817179.\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0340 - val_loss: 0.0482 - learning_rate: 7.4082e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0007334469562242892.\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0479 - learning_rate: 7.3345e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.000726149037073691.\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0478 - learning_rate: 7.2615e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0007189237334319262.\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0472 - learning_rate: 7.1892e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0007117703227626096.\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.0472 - learning_rate: 7.1177e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0007046880897187134.\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0336 - val_loss: 0.0472 - learning_rate: 7.0469e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.000697676326071031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0371 - val_loss: 0.0470 - learning_rate: 6.9768e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0006907343306373547.\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0319 - val_loss: 0.0470 - learning_rate: 6.9073e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0006838614092123559.\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0292 - val_loss: 0.0466 - learning_rate: 6.8386e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0006770568744981646.\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0319 - val_loss: 0.0476 - learning_rate: 6.7706e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0006703200460356394.\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0297 - val_loss: 0.0466 - learning_rate: 6.7032e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.0006636502501363194.\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0467 - learning_rate: 6.6365e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0006570468198150568.\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0293 - val_loss: 0.0463 - learning_rate: 6.5705e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006505090947233165.\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0466 - learning_rate: 6.5051e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006440364210831414.\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0471 - learning_rate: 6.4404e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0006376281516217733.\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0341 - val_loss: 0.0473 - learning_rate: 6.3763e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.000631283645506926.\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0287 - val_loss: 0.0497 - learning_rate: 6.3128e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0006250022682827008.\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0306 - val_loss: 0.0469 - learning_rate: 6.2500e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0006187833918061408.\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0304 - val_loss: 0.0472 - learning_rate: 6.1878e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.0006126263941844161.\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0295 - val_loss: 0.0464 - learning_rate: 6.1263e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.0006065306597126335.\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0265 - val_loss: 0.0466 - learning_rate: 6.0653e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.000600495578812266.\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.0471 - learning_rate: 6.0050e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0005945205479701944.\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0462 - learning_rate: 5.9452e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.0005886049696783552.\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0301 - val_loss: 0.0471 - learning_rate: 5.8860e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0005827482523739897.\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0461 - learning_rate: 5.8275e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.0005769498103804867.\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0271 - val_loss: 0.0467 - learning_rate: 5.7695e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.0005712090638488148.\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0275 - val_loss: 0.0474 - learning_rate: 5.7121e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0005655254386995371.\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0266 - val_loss: 0.0460 - learning_rate: 5.6553e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.000559898366565402.\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0298 - val_loss: 0.0456 - learning_rate: 5.5990e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.0005543272847345071.\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0266 - val_loss: 0.0453 - learning_rate: 5.5433e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.0005488116360940265.\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0274 - val_loss: 0.0457 - learning_rate: 5.4881e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.0005433508690744998.\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0329 - val_loss: 0.0460 - learning_rate: 5.4335e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.0005379444375946745.\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0264 - val_loss: 0.0458 - learning_rate: 5.3794e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.0005325918010068972.\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0313 - val_loss: 0.0458 - learning_rate: 5.3259e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.0005272924240430486.\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0454 - learning_rate: 5.2729e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.000522045776761016.\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0449 - learning_rate: 5.2205e-04\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.0005168513344916992.\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0263 - val_loss: 0.0456 - learning_rate: 5.1685e-04\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.0005117085777865425.\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0456 - learning_rate: 5.1171e-04\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.0005066169923655895.\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.0450 - learning_rate: 5.0662e-04\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.0005015760690660555.\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0258 - val_loss: 0.0449 - learning_rate: 5.0158e-04\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.0004965853037914095.\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0297 - val_loss: 0.0454 - learning_rate: 4.9659e-04\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.0004916441974609651.\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0215 - val_loss: 0.0449 - learning_rate: 4.9164e-04\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.0004867522559599717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0456 - learning_rate: 4.8675e-04\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.00048190899009020245.\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0252 - val_loss: 0.0450 - learning_rate: 4.8191e-04\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.0004771139155210344.\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0250 - val_loss: 0.0446 - learning_rate: 4.7711e-04\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.0004723665527410147.\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0253 - val_loss: 0.0447 - learning_rate: 4.7237e-04\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.00046766642700990925.\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0290 - val_loss: 0.0447 - learning_rate: 4.6767e-04\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.00046301306831122806.\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0445 - learning_rate: 4.6301e-04\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.00045840601130522354.\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0454 - learning_rate: 4.5841e-04\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.0004538447952823558.\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0323 - val_loss: 0.0447 - learning_rate: 4.5384e-04\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.0004493289641172216.\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0284 - val_loss: 0.0447 - learning_rate: 4.4933e-04\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.0004448580662229411.\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0440 - learning_rate: 4.4486e-04\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.0004404316545059993.\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0440 - learning_rate: 4.4043e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.0004360492863215356.\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0237 - val_loss: 0.0448 - learning_rate: 4.3605e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.00043171052342907973.\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0447 - learning_rate: 4.3171e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.0004274149319487267.\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0445 - learning_rate: 4.2741e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.00042316208231774885.\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0236 - val_loss: 0.0443 - learning_rate: 4.2316e-04\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.000418951549247639.\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0241 - val_loss: 0.0437 - learning_rate: 4.1895e-04\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.0004147829116815814.\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0253 - val_loss: 0.0436 - learning_rate: 4.1478e-04\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.0004106557527523455.\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0262 - val_loss: 0.0441 - learning_rate: 4.1066e-04\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.00040656965974059914.\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0289 - val_loss: 0.0437 - learning_rate: 4.0657e-04\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.00040252422403363596.\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0228 - val_loss: 0.0437 - learning_rate: 4.0252e-04\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.00039851904108451417.\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0246 - val_loss: 0.0439 - learning_rate: 3.9852e-04\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 0.0003945537103716011.\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0270 - val_loss: 0.0440 - learning_rate: 3.9455e-04\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.00039062783535852107.\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0256 - val_loss: 0.0430 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.00038674102345450116.\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0266 - val_loss: 0.0437 - learning_rate: 3.8674e-04\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.0003828928859751121.\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0435 - learning_rate: 3.8289e-04\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.00037908303810339886.\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0329 - val_loss: 0.0441 - learning_rate: 3.7908e-04\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.0003753110988513996.\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0260 - val_loss: 0.0439 - learning_rate: 3.7531e-04\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.0003715766910220457.\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0275 - val_loss: 0.0434 - learning_rate: 3.7158e-04\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(100, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "lr_schedule = keras.callbacks.LearningRateScheduler(exponential_decay, verbose=1)\n",
    "\n",
    "history_exp = model.fit(X_train,\n",
    "                                y_train, epochs=100, \n",
    "                                batch_size=300, \n",
    "                                validation_data=(X_val, y_val), \n",
    "                                callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: \n",
    "\n",
    "Graph the loss for the three learning schedules we have (constant, time decay, exponential decay). Zoom in on the values at the end of the training to better see the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2240b09b3a0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],label='Constant LR Training')\n",
    "plt.plot(history.history['val_loss'],label='Constant LR Validation')\n",
    "plt.plot(history_t.history['loss'], label='Time Decay LR Training')\n",
    "plt.plot(history_t.history['val_loss'], label='Time Decay LR Validation')\n",
    "plt.plot(history_exp.history['loss'], label='Exponential Decay LR Training')\n",
    "plt.plot(history_exp.history['val_loss'], label='Exponential Decay LR Validation')\n",
    "\n",
    "plt.xlim(90,100)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Comparison')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: A first convolutional neural network\n",
    "\n",
    "In the following, we try to improve on our dense NN for the MNIST image dataset with a deep convolutional network. There are two new kinds of layers that will be used, **Conv2D** and **MaxPool2D**. We will discuss this in detail next week, but for now just look at the code. While the code runs, try to figure out the structure of the network. You might want to look up these layers in the keras documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (50000, 28, 28, 1)\n",
      "y_train.shape = (50000,)\n",
      "x_val.shape = (10000, 28, 28, 1)\n",
      "y_val.shape = (10000,)\n",
      "x_test.shape = (10000, 28, 28, 1)\n",
      "y_test.shape = (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  \n",
    "\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "\tx_train, y_train, test_size = 1/6, random_state=42)\n",
    "\n",
    "print('x_train.shape =', x_train.shape)\n",
    "print('y_train.shape =', y_train.shape)\n",
    "print('x_val.shape =', x_val.shape)\n",
    "print('y_val.shape =', y_val.shape)\n",
    "print('x_test.shape =', x_test.shape)\n",
    "print('y_test.shape =', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\antho\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,510</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1960</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">125,504</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │           \u001b[38;5;34m260\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │         \u001b[38;5;34m2,510\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1960\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_97 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m125,504\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_98 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,924</span> (503.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m128,924\u001b[0m (503.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,924</span> (503.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m128,924\u001b[0m (503.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_34\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_34\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_101 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "def make_conv_model():\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Conv2D(filters = 10, kernel_size = (5,5),padding = 'Same', \n",
    "                  activation ='relu', input_shape = (28,28,1)))\n",
    "  model.add(Conv2D(filters = 10, kernel_size = (5,5),padding = 'Same', \n",
    "                  activation ='relu'))\n",
    "  model.add(MaxPool2D(pool_size=(2,2)))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(64, activation = \"relu\"))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(10, activation = \"softmax\"))\n",
    "  optimizer = keras.optimizers.Adam()\n",
    "\n",
    "  model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']) \n",
    "  return model\n",
    "\n",
    "def make_dense_model():\n",
    "  model = Sequential()\n",
    "  model.add(Flatten(input_shape = (28,28,1)))\n",
    "  model.add(Dense(512, activation = \"relu\"))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(256, activation = \"relu\"))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(10, activation = \"softmax\"))\n",
    "  optimizer = keras.optimizers.Adam()\n",
    "\n",
    "  model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']) \n",
    "  return model\n",
    "\n",
    "simple_conv_model = make_conv_model()\n",
    "dense_model = make_dense_model()\n",
    "simple_conv_model.summary()\n",
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8440 - loss: 0.5171 - val_accuracy: 0.9788 - val_loss: 0.0725\n",
      "Epoch 2/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 24ms/step - accuracy: 0.9721 - loss: 0.0922 - val_accuracy: 0.9820 - val_loss: 0.0542\n",
      "Epoch 3/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 24ms/step - accuracy: 0.9806 - loss: 0.0620 - val_accuracy: 0.9857 - val_loss: 0.0481\n",
      "Epoch 4/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - accuracy: 0.9852 - loss: 0.0478 - val_accuracy: 0.9883 - val_loss: 0.0403\n",
      "Epoch 5/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9864 - loss: 0.0425 - val_accuracy: 0.9888 - val_loss: 0.0383\n",
      "Epoch 6/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.9896 - loss: 0.0325 - val_accuracy: 0.9887 - val_loss: 0.0390\n",
      "Epoch 7/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - accuracy: 0.9907 - loss: 0.0302 - val_accuracy: 0.9876 - val_loss: 0.0447\n",
      "Epoch 8/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.9912 - loss: 0.0266 - val_accuracy: 0.9889 - val_loss: 0.0424\n",
      "Epoch 9/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9918 - loss: 0.0262 - val_accuracy: 0.9889 - val_loss: 0.0408\n",
      "Epoch 10/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9930 - loss: 0.0203 - val_accuracy: 0.9863 - val_loss: 0.0489\n",
      "Epoch 11/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9928 - loss: 0.0193 - val_accuracy: 0.9895 - val_loss: 0.0417\n",
      "Epoch 12/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9927 - loss: 0.0193 - val_accuracy: 0.9896 - val_loss: 0.0429\n",
      "Epoch 13/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 32ms/step - accuracy: 0.9957 - loss: 0.0130 - val_accuracy: 0.9901 - val_loss: 0.0447\n",
      "Epoch 14/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0144 - val_accuracy: 0.9903 - val_loss: 0.0436\n",
      "Epoch 15/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9956 - loss: 0.0140 - val_accuracy: 0.9891 - val_loss: 0.0466\n",
      "Epoch 16/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9956 - loss: 0.0124 - val_accuracy: 0.9905 - val_loss: 0.0456\n",
      "Epoch 17/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9961 - loss: 0.0127 - val_accuracy: 0.9901 - val_loss: 0.0436\n",
      "Epoch 18/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0125 - val_accuracy: 0.9898 - val_loss: 0.0474\n",
      "Epoch 19/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9967 - loss: 0.0106 - val_accuracy: 0.9906 - val_loss: 0.0474\n",
      "Epoch 20/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9961 - loss: 0.0114 - val_accuracy: 0.9897 - val_loss: 0.0498\n",
      "Epoch 21/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9970 - loss: 0.0102 - val_accuracy: 0.9888 - val_loss: 0.0523\n",
      "Epoch 22/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9969 - loss: 0.0086 - val_accuracy: 0.9898 - val_loss: 0.0554\n",
      "Epoch 23/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9965 - loss: 0.0099 - val_accuracy: 0.9893 - val_loss: 0.0543\n",
      "Epoch 24/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0082 - val_accuracy: 0.9898 - val_loss: 0.0601\n",
      "Epoch 25/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0080 - val_accuracy: 0.9905 - val_loss: 0.0550\n",
      "Epoch 26/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9971 - loss: 0.0082 - val_accuracy: 0.9906 - val_loss: 0.0546\n",
      "Epoch 27/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0073 - val_accuracy: 0.9912 - val_loss: 0.0567\n",
      "Epoch 28/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 0.9897 - val_loss: 0.0613\n",
      "Epoch 29/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9978 - loss: 0.0062 - val_accuracy: 0.9906 - val_loss: 0.0584\n",
      "Epoch 30/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9975 - loss: 0.0073 - val_accuracy: 0.9910 - val_loss: 0.0619\n",
      "Epoch 31/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0068 - val_accuracy: 0.9898 - val_loss: 0.0652\n",
      "Epoch 32/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - accuracy: 0.9972 - loss: 0.0077 - val_accuracy: 0.9902 - val_loss: 0.0657\n",
      "Epoch 33/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9979 - loss: 0.0058 - val_accuracy: 0.9908 - val_loss: 0.0632\n",
      "Epoch 34/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0060 - val_accuracy: 0.9900 - val_loss: 0.0678\n",
      "Epoch 35/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9979 - loss: 0.0057 - val_accuracy: 0.9910 - val_loss: 0.0596\n",
      "Epoch 36/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9980 - loss: 0.0059 - val_accuracy: 0.9898 - val_loss: 0.0743\n",
      "Epoch 37/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 0.9906 - val_loss: 0.0569\n",
      "Epoch 38/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9978 - loss: 0.0054 - val_accuracy: 0.9908 - val_loss: 0.0651\n",
      "Epoch 39/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9975 - loss: 0.0075 - val_accuracy: 0.9904 - val_loss: 0.0726\n",
      "Epoch 40/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0065 - val_accuracy: 0.9905 - val_loss: 0.0624\n",
      "Epoch 1/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8540 - loss: 0.4810 - val_accuracy: 0.9637 - val_loss: 0.1138\n",
      "Epoch 2/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9646 - loss: 0.1180 - val_accuracy: 0.9690 - val_loss: 0.0946\n",
      "Epoch 3/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9751 - loss: 0.0814 - val_accuracy: 0.9749 - val_loss: 0.0786\n",
      "Epoch 4/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9807 - loss: 0.0611 - val_accuracy: 0.9796 - val_loss: 0.0698\n",
      "Epoch 5/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.0489 - val_accuracy: 0.9801 - val_loss: 0.0644\n",
      "Epoch 6/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9866 - loss: 0.0411 - val_accuracy: 0.9816 - val_loss: 0.0673\n",
      "Epoch 7/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9879 - loss: 0.0390 - val_accuracy: 0.9780 - val_loss: 0.0794\n",
      "Epoch 8/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9878 - loss: 0.0357 - val_accuracy: 0.9818 - val_loss: 0.0649\n",
      "Epoch 9/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0256 - val_accuracy: 0.9821 - val_loss: 0.0741\n",
      "Epoch 10/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9907 - loss: 0.0276 - val_accuracy: 0.9816 - val_loss: 0.0691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.0250 - val_accuracy: 0.9822 - val_loss: 0.0708\n",
      "Epoch 12/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.0242 - val_accuracy: 0.9814 - val_loss: 0.0789\n",
      "Epoch 13/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.0222 - val_accuracy: 0.9843 - val_loss: 0.0677\n",
      "Epoch 14/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0217 - val_accuracy: 0.9837 - val_loss: 0.0724\n",
      "Epoch 15/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9929 - loss: 0.0198 - val_accuracy: 0.9815 - val_loss: 0.0923\n",
      "Epoch 16/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9932 - loss: 0.0208 - val_accuracy: 0.9819 - val_loss: 0.0851\n",
      "Epoch 17/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0154 - val_accuracy: 0.9831 - val_loss: 0.0893\n",
      "Epoch 18/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9940 - loss: 0.0171 - val_accuracy: 0.9831 - val_loss: 0.0824\n",
      "Epoch 19/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0171 - val_accuracy: 0.9827 - val_loss: 0.0820\n",
      "Epoch 20/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0148 - val_accuracy: 0.9826 - val_loss: 0.0881\n",
      "Epoch 21/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9950 - loss: 0.0155 - val_accuracy: 0.9844 - val_loss: 0.0797\n",
      "Epoch 22/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9960 - loss: 0.0126 - val_accuracy: 0.9847 - val_loss: 0.0823\n",
      "Epoch 23/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9952 - loss: 0.0151 - val_accuracy: 0.9837 - val_loss: 0.0865\n",
      "Epoch 24/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0163 - val_accuracy: 0.9830 - val_loss: 0.0873\n",
      "Epoch 25/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9959 - loss: 0.0132 - val_accuracy: 0.9834 - val_loss: 0.0996\n",
      "Epoch 26/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9947 - loss: 0.0194 - val_accuracy: 0.9841 - val_loss: 0.0873\n",
      "Epoch 27/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9972 - loss: 0.0091 - val_accuracy: 0.9815 - val_loss: 0.1027\n",
      "Epoch 28/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0154 - val_accuracy: 0.9834 - val_loss: 0.0932\n",
      "Epoch 29/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9962 - loss: 0.0118 - val_accuracy: 0.9840 - val_loss: 0.0824\n",
      "Epoch 30/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.0163 - val_accuracy: 0.9845 - val_loss: 0.0897\n",
      "Epoch 31/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0108 - val_accuracy: 0.9817 - val_loss: 0.1009\n",
      "Epoch 32/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9960 - loss: 0.0129 - val_accuracy: 0.9837 - val_loss: 0.0928\n",
      "Epoch 33/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0112 - val_accuracy: 0.9859 - val_loss: 0.0927\n",
      "Epoch 34/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 0.9825 - val_loss: 0.1073\n",
      "Epoch 35/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9965 - loss: 0.0116 - val_accuracy: 0.9838 - val_loss: 0.0956\n",
      "Epoch 36/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9959 - loss: 0.0152 - val_accuracy: 0.9845 - val_loss: 0.0959\n",
      "Epoch 37/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0110 - val_accuracy: 0.9826 - val_loss: 0.1118\n",
      "Epoch 38/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9959 - loss: 0.0158 - val_accuracy: 0.9847 - val_loss: 0.0949\n",
      "Epoch 39/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9971 - loss: 0.0091 - val_accuracy: 0.9853 - val_loss: 0.0915\n",
      "Epoch 40/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0089 - val_accuracy: 0.9856 - val_loss: 0.0920\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "batch_size = 86\n",
    "\n",
    "simple_conv_history = simple_conv_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val), verbose=1)\n",
    "dense_history = dense_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9869 - loss: 0.0672\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.1161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22409aedc40>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_conv_test_loss, simple_conv_test_acc = simple_conv_model.evaluate(x_test, y_test)\n",
    "dense_test_loss, dense_test_acc = dense_model.evaluate(x_test, y_test)\n",
    "\n",
    "plt.plot(dense_history.history[\"accuracy\"], \"b--\",label=\"dense training accuracy\")\n",
    "plt.plot(dense_history.history[\"val_accuracy\"], \"b-\",label=\"dense val accuracy\")\n",
    "plt.axhline(dense_test_acc, color=\"k\", linestyle=\":\", label=\"dense test accuracy\")\n",
    "plt.plot(simple_conv_history.history[\"accuracy\"], \"g--\",label=\"simple conv training accuracy\")\n",
    "plt.plot(simple_conv_history.history[\"val_accuracy\"], \"g-\",label=\"simple conv val accuracy\")\n",
    "plt.axhline(simple_conv_test_acc,color=\"k\", linestyle=\"--\", label=\"simple conv test accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0.94, 1.005)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
