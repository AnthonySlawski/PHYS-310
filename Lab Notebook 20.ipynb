{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIb7AW-J_Q0j"
   },
   "source": [
    "# Lab Notebook 20\n",
    "\n",
    "In this notebook, we use a fully connected neural network to solve a previously seen problem in regression: the photometric redshift problem  We also explore the effect of loss function and learning rate schedule. \n",
    "\n",
    "*Modified from: Copyright: Viviana Acquaviva (2023). License: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "wCi2a2GB_Q0m"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential #the model is built adding layers one after the other\n",
    "from keras.layers import Dense #fully connected layers: every output talks to every input\n",
    "from keras.layers import Dropout #for regularization\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RELqQBID_Q0n"
   },
   "source": [
    "# Part 1: PhotoZ regression with a deep NN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLHnWtsJ_Q04"
   },
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6-Ir38f_Q05"
   },
   "source": [
    "Let us begin with the reduced (high-quality) data set we used for Bagging and Boosting methods. For reference, our best model achieved an outlier fraction of 4%.\n",
    "\n",
    "Read in 'sel_features.csv' and 'sel_target.csv' as X and y, respectively. You will need to shuffle X and y (use random_state=12) as we did in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "e8hFO3qM_Q05"
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('sel_features.csv', sep='\\t')\n",
    "y = pd.read_csv('sel_target.csv', sep='\\t')\n",
    "\n",
    "X, y = shuffle(X, y, random_state = 12)#seed to 12 for same 'random' results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the data into fifths; we would like to use a 60/20/20 split for training/validation/test. Define these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6307, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_apercor</th>\n",
       "      <th>g_apercor</th>\n",
       "      <th>r_apercor</th>\n",
       "      <th>i_apercor</th>\n",
       "      <th>z_apercor</th>\n",
       "      <th>y_apercor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>23.7774</td>\n",
       "      <td>23.4961</td>\n",
       "      <td>23.2445</td>\n",
       "      <td>22.9700</td>\n",
       "      <td>22.5860</td>\n",
       "      <td>22.4497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675</th>\n",
       "      <td>23.7430</td>\n",
       "      <td>23.3638</td>\n",
       "      <td>22.6674</td>\n",
       "      <td>21.7934</td>\n",
       "      <td>21.2195</td>\n",
       "      <td>21.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>24.1826</td>\n",
       "      <td>23.1667</td>\n",
       "      <td>22.6836</td>\n",
       "      <td>22.4811</td>\n",
       "      <td>22.3890</td>\n",
       "      <td>22.4926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>23.6480</td>\n",
       "      <td>23.2737</td>\n",
       "      <td>22.6016</td>\n",
       "      <td>22.3798</td>\n",
       "      <td>22.3236</td>\n",
       "      <td>22.3666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>24.0790</td>\n",
       "      <td>23.7875</td>\n",
       "      <td>23.3592</td>\n",
       "      <td>22.6754</td>\n",
       "      <td>22.4678</td>\n",
       "      <td>22.4220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      u_apercor  g_apercor  r_apercor  i_apercor  z_apercor  y_apercor\n",
       "4561    23.7774    23.4961    23.2445    22.9700    22.5860    22.4497\n",
       "3675    23.7430    23.3638    22.6674    21.7934    21.2195    21.0882\n",
       "3201    24.1826    23.1667    22.6836    22.4811    22.3890    22.4926\n",
       "780     23.6480    23.2737    22.6016    22.3798    22.3236    22.3666\n",
       "4205    24.0790    23.7875    23.3592    22.6754    22.4678    22.4220"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6307, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zhelio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4561</th>\n",
       "      <td>1.3944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3675</th>\n",
       "      <td>0.9846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>0.1683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>0.4280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>0.8421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      zhelio\n",
       "4561  1.3944\n",
       "3675  0.9846\n",
       "3201  0.1683\n",
       "780   0.4280\n",
       "4205  0.8421"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: 60% for training, 40% for the combination of validation and testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=12)\n",
    "\n",
    "# Second split: Split the temporary set into 50% validation, 50% test (20% of the original dataset each)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aHqfJPv_Q05"
   },
   "source": [
    "We know that we need to scale our data! Do so below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1685403021297,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "lGcMKwtu_Q05",
    "outputId": "1bd10c4d-8302-408a-b51a-5e416d314aed"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1zYQ1yg_Q06"
   },
   "source": [
    "## Step 2\n",
    "\n",
    "In a regression problem, we will choose a different activation for the output layer (linear), and an appropriate loss function (MSE). Our input layer has **six neurons** for this problem. For other parameters and the network structure, we can start with two relu-activated layers with **100 neurons** and go from there.\n",
    "\n",
    "1. Define your model using \"Sequential()\".\n",
    "2. Define your optimizer using the Adam optimizer from keras, and use the default learning rate of 0.001.\n",
    "3. Add an input layer and specify a size of 100 neurons (size=number of original features).\n",
    "4. Add one hidden layer and specify 100 neurons.\n",
    "5. Add an output layer with one neuron\n",
    "6. Finally, compile your model using MSE as the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layer\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "# Define the rest of the model architecture\n",
    "model = Sequential([\n",
    "    Input(shape=(6,)),  # Input layer with 6 neurons\n",
    "    Dense(100, activation='relu'),  # First hidden layer with 100 neurons\n",
    "    Dense(100, activation='relu'),  # Second hidden layer with 100 neurons\n",
    "    Dense(1, activation='linear')  # Output layer with 1 neuron\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_pO8Jjl_Q06"
   },
   "source": [
    "To create your neural network, fit your model and use 100 epochs and batch size = 300:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17829,
     "status": "ok",
     "timestamp": 1685403046028,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "EpC58myL_Q06",
    "outputId": "dba21fd1-fc42-4061-d3f0-33095bc5a504",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.3843 - val_loss: 0.2075\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1698 - val_loss: 0.0946\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0858 - val_loss: 0.0528\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0601 - val_loss: 0.0416\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0402 - val_loss: 0.0387\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0479 - val_loss: 0.0367\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0415 - val_loss: 0.0356\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0389 - val_loss: 0.0360\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0388 - val_loss: 0.0367\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0439 - val_loss: 0.0349\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0356 - val_loss: 0.0346\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0391 - val_loss: 0.0344\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0323 - val_loss: 0.0337\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0388 - val_loss: 0.0334\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0325 - val_loss: 0.0330\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0377 - val_loss: 0.0331\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0349 - val_loss: 0.0331\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0319 - val_loss: 0.0331\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0479 - val_loss: 0.0338\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0347 - val_loss: 0.0338\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0393 - val_loss: 0.0329\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0249 - val_loss: 0.0322\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0284 - val_loss: 0.0322\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0331 - val_loss: 0.0332\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0341 - val_loss: 0.0323\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0299 - val_loss: 0.0329\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0279 - val_loss: 0.0333\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0369 - val_loss: 0.0331\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0291 - val_loss: 0.0323\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0263 - val_loss: 0.0328\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0315\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0321 - val_loss: 0.0332\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0320\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0275 - val_loss: 0.0320\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0293 - val_loss: 0.0324\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0235 - val_loss: 0.0321\n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0235 - val_loss: 0.0317\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0322\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0261 - val_loss: 0.0321\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0310 - val_loss: 0.0323\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0237 - val_loss: 0.0318\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0248 - val_loss: 0.0326\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0335\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0216 - val_loss: 0.0311\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0266 - val_loss: 0.0324\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0237 - val_loss: 0.0321\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0262 - val_loss: 0.0324\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0198 - val_loss: 0.0337\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0266 - val_loss: 0.0323\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0261 - val_loss: 0.0343\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0310\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0323\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0263 - val_loss: 0.0315\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0250 - val_loss: 0.0320\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0225 - val_loss: 0.0317\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0339\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0245 - val_loss: 0.0323\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0253 - val_loss: 0.0317\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0206 - val_loss: 0.0322\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0225 - val_loss: 0.0319\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0191 - val_loss: 0.0315\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0208 - val_loss: 0.0318\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0210 - val_loss: 0.0319\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0237 - val_loss: 0.0310\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0210 - val_loss: 0.0319\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0196 - val_loss: 0.0333\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0241 - val_loss: 0.0328\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0256 - val_loss: 0.0328\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0251 - val_loss: 0.0315\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0331\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0250 - val_loss: 0.0317\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0201 - val_loss: 0.0324\n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0205 - val_loss: 0.0316\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0324\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0236 - val_loss: 0.0307\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0199 - val_loss: 0.0312\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0320\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0189 - val_loss: 0.0312\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0212 - val_loss: 0.0321\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0224 - val_loss: 0.0326\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0235 - val_loss: 0.0333\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0176 - val_loss: 0.0320\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0321\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0191 - val_loss: 0.0311\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0218 - val_loss: 0.0315\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0176 - val_loss: 0.0318\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0210 - val_loss: 0.0309\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - val_loss: 0.0329\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0341\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0228 - val_loss: 0.0309\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0181 - val_loss: 0.0304\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0189 - val_loss: 0.0315\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0201 - val_loss: 0.0307\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0194 - val_loss: 0.0320\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0197 - val_loss: 0.0321\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0213 - val_loss: 0.0322\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182 - val_loss: 0.0309\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0175 - val_loss: 0.0324\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0194 - val_loss: 0.0312\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0181 - val_loss: 0.0322\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=300,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use \"model.evaluate\" to find the MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1685403046029,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "R9F0vSIG_Q07",
    "outputId": "3acbecba-51eb-471b-ba8d-7b9f98ea56d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0288 \n",
      "Mean Squared Error: 0.0292167067527771\n"
     ]
    }
   ],
   "source": [
    "mse = model.evaluate(X_test,y_test)\n",
    "print('Mean Squared Error:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6o1--T2H_Q07"
   },
   "source": [
    "## Step 3\n",
    "\n",
    "As in the previous lab, we can plot the loss as a function of epoch from the train and validation data sets. Here the loss is of course the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 982
    },
    "executionInfo": {
     "elapsed": 938,
     "status": "ok",
     "timestamp": 1685403046962,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "igJTaSwy_Q07",
    "outputId": "0375ff29-c1c5-4e19-850c-f88c516407cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x229eb016f70>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Npn26F0Uo0X3"
   },
   "source": [
    "As always with regression problems, it is helpful to plot the predictions against the true values. Plot estimated redshift versus true redshift in a scatter plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3269,
     "status": "ok",
     "timestamp": 1685403054362,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "4j5LEBae_Q07",
    "outputId": "19fe2018-555e-4779-96a8-4ede8522a99f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.title('Estimated Redshift vs True Redshift')\n",
    "plt.xlabel('True Redshift')\n",
    "plt.ylabel('Estimated Redshift')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AISbbpfKo-nn"
   },
   "source": [
    "## Step 4\n",
    "\n",
    "We didn't do cross validation, so we can only generate predictions on our single test fold in order to derive the other metrics we are interested in.\n",
    "\n",
    "First, calculate the Outlier Fraction (OLF):\n",
    "\n",
    "$\\mathrm{OLF} = \\mathrm{num}\\left ( \\frac{|\\Delta z|}{1+z_{\\mathrm{true}}} > 0.15 = \\mathrm{true} \\right)/N$\n",
    "\n",
    "*The numerator is the number of instances where $\\frac{|\\Delta z|}{1+z_{\\mathrm{true}}}>0.15$ is true. $N$ is the length of $y_{\\mathrm{test}}$.*\n",
    "\n",
    "We can also calculate the Normalized Median Absolute Deviation (NMAD):\n",
    "\n",
    "$\\sigma_{\\mathrm{NMAD}}=1.48 \\times \\mathrm{median}\\left ( \\frac{|\\Delta z|}{1+z_{\\mathrm{true}}}\\right )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1685403054567,
     "user": {
      "displayName": "Viviana Acquaviva",
      "userId": "16294609486294432741"
     },
     "user_tz": 240
    },
    "id": "jB8PgXsG_Q08",
    "outputId": "d0001149-d329-4b15-d9de-8fdda7ad1926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Fraction: 0.04374577971702239\n",
      "Normalized Median Absolute Deviation: 0.2884155456648643\n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute differences between predicted and actual values\n",
    "dz = np.abs(predictions.flatten() - y_test.values.flatten())\n",
    "\n",
    "# Identify outliers where actual values are greater than 0.15\n",
    "outliers = np.where(y_test.values.flatten() > 0.15, 1, 0)\n",
    "\n",
    "# Calculate the Outlier Fraction (OLF) for outliers\n",
    "OLF = np.sum(dz[outliers == 1] / (1 + y_test.values.flatten()[outliers == 1])) / len(y_test)\n",
    "\n",
    "# Calculate the Normalized Median Absolute Deviation (NMAD) for non-outliers\n",
    "NMAD = 1.48 * np.median(dz[outliers == 0] / (1 + y_test.values.flatten()[outliers == 0]))\n",
    "\n",
    "# Print the Outlier Fraction and Normalized Median Absolute Deviation\n",
    "print('Outlier Fraction:', OLF)\n",
    "print('Normalized Median Absolute Deviation:', NMAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Effect of loss function\n",
    "\n",
    "So far, we have used the MSE loss in our training, but this choice is not unique. Would using the MAE or MAPE loss functions give better results for the OLF and NMAD parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5637 - val_loss: 0.3970\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3486 - val_loss: 0.2543\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2317 - val_loss: 0.1594\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1535 - val_loss: 0.1164\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1177 - val_loss: 0.1126\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1137 - val_loss: 0.1039\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1029 - val_loss: 0.0998\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0976 - val_loss: 0.1016\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0961 - val_loss: 0.1000\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0970 - val_loss: 0.0959\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0907 - val_loss: 0.0977\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0971 - val_loss: 0.0900\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0913 - val_loss: 0.0891\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0913 - val_loss: 0.0877\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0876 - val_loss: 0.0861\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0853 - val_loss: 0.0850\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0846 - val_loss: 0.0844\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0829 - val_loss: 0.0867\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0831 - val_loss: 0.0845\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0815 - val_loss: 0.0862\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0808 - val_loss: 0.0820\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0807 - val_loss: 0.0819\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0810 - val_loss: 0.0823\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0785 - val_loss: 0.0816\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0769 - val_loss: 0.0799\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0805 - val_loss: 0.0839\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0783 - val_loss: 0.0814\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0790 - val_loss: 0.0798\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0752 - val_loss: 0.0794\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0778 - val_loss: 0.0784\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0733 - val_loss: 0.0794\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0754 - val_loss: 0.0773\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0773 - val_loss: 0.0827\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0788 - val_loss: 0.0778\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0701 - val_loss: 0.0787\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0756 - val_loss: 0.0773\n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0750 - val_loss: 0.0775\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0766 - val_loss: 0.0768\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0742 - val_loss: 0.0771\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0727 - val_loss: 0.0762\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0750 - val_loss: 0.0775\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0703 - val_loss: 0.0771\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0689 - val_loss: 0.0745\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0661 - val_loss: 0.0763\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0702 - val_loss: 0.0747\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0731 - val_loss: 0.0757\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0742 - val_loss: 0.0767\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0784 - val_loss: 0.0741\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0728 - val_loss: 0.0745\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0697 - val_loss: 0.0742\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0690 - val_loss: 0.0741\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0713 - val_loss: 0.0728\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0700 - val_loss: 0.0725\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0642 - val_loss: 0.0764\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0686 - val_loss: 0.0730\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0651 - val_loss: 0.0740\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0695 - val_loss: 0.0746\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0696 - val_loss: 0.0719\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0673 - val_loss: 0.0721\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0663 - val_loss: 0.0746\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0674 - val_loss: 0.0704\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0655 - val_loss: 0.0757\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0679 - val_loss: 0.0711\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0680 - val_loss: 0.0707\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0630 - val_loss: 0.0703\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0679 - val_loss: 0.0706\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0646 - val_loss: 0.0701\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0668 - val_loss: 0.0689\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0620 - val_loss: 0.0687\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0613 - val_loss: 0.0699\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0642 - val_loss: 0.0683\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0671 - val_loss: 0.0685\n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0603 - val_loss: 0.0690\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0671 - val_loss: 0.0687\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0641 - val_loss: 0.0678\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0633 - val_loss: 0.0680\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0650 - val_loss: 0.0726\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0650 - val_loss: 0.0675\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0604 - val_loss: 0.0668\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0601 - val_loss: 0.0680\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0609 - val_loss: 0.0686\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0615 - val_loss: 0.0684\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0618 - val_loss: 0.0663\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0616 - val_loss: 0.0687\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0631 - val_loss: 0.0676\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0616 - val_loss: 0.0649\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0580 - val_loss: 0.0663\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0569 - val_loss: 0.0654\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0582 - val_loss: 0.0665\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0633 - val_loss: 0.0684\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0622 - val_loss: 0.0661\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0593 - val_loss: 0.0648\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0562 - val_loss: 0.0641\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0580 - val_loss: 0.0657\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0608 - val_loss: 0.0646\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0620 - val_loss: 0.0647\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0593 - val_loss: 0.0633\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0606 - val_loss: 0.0655\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0593 - val_loss: 0.0633\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0568 - val_loss: 0.0634\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.0614\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss Function: mean_absolute_error\n",
      "Outlier Fraction (OLF): 0.03179790093235916\n",
      "Normalized Median Absolute Deviation (NMAD): 0.08327881696215585\n",
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 116.3379 - val_loss: 14.4632\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 241.1237 - val_loss: 17.0787\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 169.1760 - val_loss: 20.9959\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 40.0131 - val_loss: 22.5801\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.9184 - val_loss: 24.0008\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 23.1752 - val_loss: 19.1991\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 95.9717 - val_loss: 18.3497\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 52.1325 - val_loss: 19.0669\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.7611 - val_loss: 17.7896\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 58.3796 - val_loss: 18.9157\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 35.1087 - val_loss: 17.2747\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.8666 - val_loss: 17.8270\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.3638 - val_loss: 16.2085\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 38.4609 - val_loss: 18.1146\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.2755 - val_loss: 15.8418\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40.6910 - val_loss: 15.7138\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.7210 - val_loss: 15.8734\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.2316 - val_loss: 15.3165\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7882 - val_loss: 14.4730\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 49.1328 - val_loss: 17.2768\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 114.6894 - val_loss: 17.6730\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.3354 - val_loss: 15.5667\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.1032 - val_loss: 16.2718\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.7692 - val_loss: 15.8310\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25.9004 - val_loss: 17.9262\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 59.5567 - val_loss: 13.6839\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.5331 - val_loss: 14.7987\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.7597 - val_loss: 16.3280\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 51.3282 - val_loss: 15.2146\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.2520 - val_loss: 16.5573\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 35.7452 - val_loss: 13.9518\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25.5149 - val_loss: 17.1137\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 24.4709 - val_loss: 16.2583\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.3445 - val_loss: 14.9446\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 69.5948 - val_loss: 13.5199\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1619 - val_loss: 15.7651\n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.0801 - val_loss: 17.0577\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22.7403 - val_loss: 15.3462\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.3209 - val_loss: 14.7923\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 47.6684 - val_loss: 15.0451\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.0496 - val_loss: 15.1258\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26.5496 - val_loss: 14.9007\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17.4596 - val_loss: 13.4054\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24.3230 - val_loss: 12.7404\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.9016 - val_loss: 15.9895\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 84.0366 - val_loss: 14.7776\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.9022 - val_loss: 13.1291\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 41.9088 - val_loss: 13.4817\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.9796 - val_loss: 13.9254\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36.0487 - val_loss: 14.0091\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.2922 - val_loss: 14.6532\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.1358 - val_loss: 13.7356\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.1627 - val_loss: 13.9954\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.3308 - val_loss: 13.4781\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.6343 - val_loss: 12.5789\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37.1556 - val_loss: 13.7262\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 31.6555 - val_loss: 13.9942\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.2238 - val_loss: 13.3082\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.2291 - val_loss: 13.6653\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.1247 - val_loss: 13.5210\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.6285 - val_loss: 13.7213\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.0631 - val_loss: 12.7940\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15.6857 - val_loss: 12.2419\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.7910 - val_loss: 13.8591\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.3426 - val_loss: 14.5958\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.7785 - val_loss: 14.1088\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.3411 - val_loss: 12.8173\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.1888 - val_loss: 11.5344\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.5603 - val_loss: 12.6782\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.4792 - val_loss: 14.6777\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.0615 - val_loss: 14.7426\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 41.8853 - val_loss: 14.2110\n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.5796 - val_loss: 13.9933\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 27.0707 - val_loss: 12.2669\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.8376 - val_loss: 13.7779\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.6328 - val_loss: 13.0113\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.4627 - val_loss: 13.6151\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 62.3729 - val_loss: 11.6491\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.6788 - val_loss: 12.3949\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.4366 - val_loss: 12.4652\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24.3555 - val_loss: 13.1416\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.6485 - val_loss: 12.8405\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15.9550 - val_loss: 12.8482\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.4475 - val_loss: 12.7865\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 24.5331 - val_loss: 13.4187\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.7880 - val_loss: 11.7943\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.5337 - val_loss: 12.5336\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.5535 - val_loss: 14.2037\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.2637 - val_loss: 14.1051\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 25.1798 - val_loss: 13.5928\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 61.9815 - val_loss: 12.4500\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.8986 - val_loss: 12.5310\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.2204 - val_loss: 15.2610\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 52.3477 - val_loss: 12.4604\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 49.1287 - val_loss: 13.6862\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.7408 - val_loss: 12.7869\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 43.4074 - val_loss: 12.1381\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.5403 - val_loss: 12.1101\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.5772 - val_loss: 12.6639\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.4695 - val_loss: 12.1849\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.6477 \n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Loss Function: mean_absolute_percentage_error\n",
      "Outlier Fraction (OLF): 0.04177290095708726\n",
      "Normalized Median Absolute Deviation (NMAD): 0.0501536803600564\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the neural network\n",
    "model = Sequential([\n",
    "    Input(shape=(6,)),  # Input layer with 6 neurons\n",
    "    Dense(100, activation='relu'),  # First hidden layer with 100 neurons\n",
    "    Dense(100, activation='relu'),  # Second hidden layer with 100 neurons\n",
    "    Dense(1, activation='linear')  # Output layer with 1 neuron\n",
    "])\n",
    "\n",
    "\n",
    "# For each loss function: MAE and MAPE\n",
    "for loss_function in ['mean_absolute_error', 'mean_absolute_percentage_error']:\n",
    "    # Compile the model with Adam optimizer and the selected loss function\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_function)\n",
    "    \n",
    "    #train\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=300, validation_data=(X_val, y_val))\n",
    "    \n",
    "    # Evaluate \n",
    "    model.evaluate(X_test, y_test)\n",
    "    \n",
    "    # Predictions on test data\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Absolute differences between predictions and actual values\n",
    "    dz = np.abs(predictions.flatten() - y_test.values.flatten())\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers = np.where(y_test.values.flatten() > 0.15, 1, 0)\n",
    "    \n",
    "    # Calculate OLF for outliers\n",
    "    OLF = np.sum(dz[outliers == 1] / (1 + y_test.values.flatten()[outliers == 1])) / len(y_test)\n",
    "    \n",
    "    # Calculate NMAD for non-outliers\n",
    "    NMAD = 1.48 * np.median(dz[outliers == 0] / (1 + y_test.values.flatten()[outliers == 0]))\n",
    "    \n",
    "    print('Loss Function:',loss_function)\n",
    "    print('Outlier Fraction (OLF):', OLF)\n",
    "    print('Normalized Median Absolute Deviation (NMAD):', NMAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE loss gives the better overall results for the OLF and NMAD parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Effect of learning rate schedules\n",
    "\n",
    "When training a neural network, we can tune the performance by optimizing a large set of hyperparameters. Last time, we looked at the choice of optimizer and regularization. Another important parameter is the learning rate. A learning rate that is set too small will slow down the training, as we update the weights of the network in tiny steps. On the other hand, if the learning rate is set too high, the training can diverge. Usually we want to start with a large learning rate to make fast progress and then slow down the training close to the optimum. This can be achieved by using learning rate schedules, which we will investigate in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Time based-decay\n",
    "\n",
    "First we can try a time-based decay:\n",
    "$$\\eta(t)=\\eta_0/(1+t⋅\\eta_0/n_{epochs})$$\n",
    "\n",
    "where $\\eta_0$ is the initial learning rate, $t$ the iteration number (epoch) and $n_{epochs}$ the total number of epochs. \n",
    "\n",
    "Write a function (i.e the learning schedule) that implements this learning schedule. The function takes an epoch index (integer, indexed from 0) and current learning rate (float) as inputs and returns a new learning rate as output (float). In our case, the current learning rate is not actually used in the function, but this format is expected when we use it in keras later. Set the initial learning rate to 0.001 and the number of epochs to 100. Make a plot of the learning rate as a function of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_based_decay(epoch, cur_lr):\n",
    "    init_lr = 0.001\n",
    "    epochs = 100\n",
    "    decay_rate = init_lr / epochs\n",
    "    new_lr = init_lr / (1 + epoch * decay_rate)\n",
    "    return new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Learning Rate')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs=range(100)\n",
    "learning_rates=[time_based_decay(epoch, 0) for epoch in epochs]\n",
    "plt.plot(epochs,learning_rates)\n",
    "plt.title('Learning Rate Schedule: Time-based Decay')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with this new learning rate schedule, and save the history. Remember to rebuild the model to re-initialize all weights and biases. To use the learning rate schedule, add **callbacks=[keras.callbacks.LearningRateScheduler(my_function, verbose=1)]** to model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.4148 - val_loss: 0.2563 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0009999900000999989.\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2079 - val_loss: 0.1362 - learning_rate: 9.9999e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.000999980000399992.\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1078 - val_loss: 0.0779 - learning_rate: 9.9998e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.000999970000899973.\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0591 - val_loss: 0.0614 - learning_rate: 9.9997e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.000999960001599936.\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0481 - val_loss: 0.0559 - learning_rate: 9.9996e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.000999950002499875.\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0418 - val_loss: 0.0549 - learning_rate: 9.9995e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.000999940003599784.\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0472 - val_loss: 0.0549 - learning_rate: 9.9994e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.000999930004899657.\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0457 - val_loss: 0.0534 - learning_rate: 9.9993e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.000999920006399488.\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0445 - val_loss: 0.0527 - learning_rate: 9.9992e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0009999100080992712.\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0435 - val_loss: 0.0522 - learning_rate: 9.9991e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.000999900009999.\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0397 - val_loss: 0.0520 - learning_rate: 9.9990e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.000999890012098669.\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0429 - val_loss: 0.0511 - learning_rate: 9.9989e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0009998800143982724.\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0422 - val_loss: 0.0508 - learning_rate: 9.9988e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0009998700168978034.\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0395 - val_loss: 0.0514 - learning_rate: 9.9987e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0009998600195972563.\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0358 - val_loss: 0.0505 - learning_rate: 9.9986e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0009998500224966255.\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0333 - val_loss: 0.0499 - learning_rate: 9.9985e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0009998400255959048.\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0341 - val_loss: 0.0498 - learning_rate: 9.9984e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0009998300288950879.\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0499 - learning_rate: 9.9983e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.000999820032394169.\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0353 - val_loss: 0.0496 - learning_rate: 9.9982e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0009998100360931424.\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0331 - val_loss: 0.0494 - learning_rate: 9.9981e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0009998000399920016.\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.0492 - learning_rate: 9.9980e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000999790044090741.\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.0485 - learning_rate: 9.9979e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0009997800483893542.\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0480 - learning_rate: 9.9978e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.000999770052887836.\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0302 - val_loss: 0.0483 - learning_rate: 9.9977e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0009997600575861792.\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0327 - val_loss: 0.0490 - learning_rate: 9.9976e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0009997500624843788.\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0324 - val_loss: 0.0481 - learning_rate: 9.9975e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0009997400675824286.\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0480 - learning_rate: 9.9974e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0009997300728803223.\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0480 - learning_rate: 9.9973e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0009997200783780542.\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0344 - val_loss: 0.0480 - learning_rate: 9.9972e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0009997100840756182.\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0287 - val_loss: 0.0477 - learning_rate: 9.9971e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.000999700089973008.\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0321 - val_loss: 0.0477 - learning_rate: 9.9970e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0009996900960702183.\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0469 - learning_rate: 9.9969e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0009996801023672425.\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0406 - val_loss: 0.0476 - learning_rate: 9.9968e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.000999670108864075.\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.0470 - learning_rate: 9.9967e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0009996601155607093.\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0309 - val_loss: 0.0472 - learning_rate: 9.9966e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0009996501224571398.\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0471 - learning_rate: 9.9965e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0009996401295533609.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0469 - learning_rate: 9.9964e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0009996301368493659.\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0479 - learning_rate: 9.9963e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0009996201443451488.\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0349 - val_loss: 0.0487 - learning_rate: 9.9962e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0009996101520407042.\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0471 - learning_rate: 9.9961e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0009996001599360256.\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0338 - val_loss: 0.0469 - learning_rate: 9.9960e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.0009995901680311073.\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0309 - val_loss: 0.0467 - learning_rate: 9.9959e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0009995801763259431.\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0471 - learning_rate: 9.9958e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0009995701848205273.\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.0461 - learning_rate: 9.9957e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0009995601935148535.\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.0463 - learning_rate: 9.9956e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0009995502024089159.\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0474 - learning_rate: 9.9955e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.000999540211502709.\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0274 - val_loss: 0.0459 - learning_rate: 9.9954e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.000999530220796226.\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0316 - val_loss: 0.0461 - learning_rate: 9.9953e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.000999520230289461.\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0314 - val_loss: 0.0463 - learning_rate: 9.9952e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.0009995102399824086.\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0269 - val_loss: 0.0456 - learning_rate: 9.9951e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.0009995002498750627.\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0325 - val_loss: 0.0456 - learning_rate: 9.9950e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.0009994902599674165.\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0461 - learning_rate: 9.9949e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.000999480270259465.\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0283 - val_loss: 0.0467 - learning_rate: 9.9948e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.000999470280751202.\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0459 - learning_rate: 9.9947e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.000999460291442621.\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0268 - val_loss: 0.0470 - learning_rate: 9.9946e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.0009994503023337165.\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0454 - learning_rate: 9.9945e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.0009994403134244824.\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0228 - val_loss: 0.0469 - learning_rate: 9.9944e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0009994303247149127.\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0462 - learning_rate: 9.9943e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.0009994203362050011.\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0242 - val_loss: 0.0474 - learning_rate: 9.9942e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.000999410347894742.\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0252 - val_loss: 0.0457 - learning_rate: 9.9941e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.0009994003597841297.\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0279 - val_loss: 0.0457 - learning_rate: 9.9940e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.0009993903718731574.\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0244 - val_loss: 0.0452 - learning_rate: 9.9939e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.0009993803841618196.\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0447 - learning_rate: 9.9938e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.0009993703966501106.\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0446 - learning_rate: 9.9937e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.0009993604093380237.\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0455 - learning_rate: 9.9936e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.0009993504222255533.\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0455 - learning_rate: 9.9935e-04\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.0009993404353126935.\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0303 - val_loss: 0.0447 - learning_rate: 9.9934e-04\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.0009993304485994385.\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0443 - learning_rate: 9.9933e-04\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.0009993204620857817.\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0222 - val_loss: 0.0462 - learning_rate: 9.9932e-04\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.0009993104757717174.\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0454 - learning_rate: 9.9931e-04\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.00099930048965724.\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0245 - val_loss: 0.0452 - learning_rate: 9.9930e-04\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.0009992905037423429.\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0258 - val_loss: 0.0454 - learning_rate: 9.9929e-04\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.0009992805180270205.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0262 - val_loss: 0.0489 - learning_rate: 9.9928e-04\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.0009992705325112669.\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0313 - val_loss: 0.0455 - learning_rate: 9.9927e-04\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.0009992605471950758.\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0231 - val_loss: 0.0448 - learning_rate: 9.9926e-04\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.0009992505620784412.\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0217 - val_loss: 0.0452 - learning_rate: 9.9925e-04\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.0009992405771613573.\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0270 - val_loss: 0.0452 - learning_rate: 9.9924e-04\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.0009992305924438184.\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0453 - learning_rate: 9.9923e-04\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.0009992206079258179.\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0461 - learning_rate: 9.9922e-04\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.0009992106236073502.\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0268 - val_loss: 0.0454 - learning_rate: 9.9921e-04\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.0009992006394884093.\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0226 - val_loss: 0.0451 - learning_rate: 9.9920e-04\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.0009991906555689891.\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0254 - val_loss: 0.0464 - learning_rate: 9.9919e-04\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.0009991806718490836.\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0466 - learning_rate: 9.9918e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.0009991706883286872.\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0263 - val_loss: 0.0457 - learning_rate: 9.9917e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.0009991607050077935.\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0255 - val_loss: 0.0462 - learning_rate: 9.9916e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.0009991507218863967.\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0258 - val_loss: 0.0452 - learning_rate: 9.9915e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.0009991407389644904.\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0274 - val_loss: 0.0451 - learning_rate: 9.9914e-04\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.0009991307562420696.\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0449 - learning_rate: 9.9913e-04\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.0009991207737191272.\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0210 - val_loss: 0.0452 - learning_rate: 9.9912e-04\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.0009991107913956579.\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0210 - val_loss: 0.0457 - learning_rate: 9.9911e-04\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.0009991008092716557.\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0457 - learning_rate: 9.9910e-04\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.0009990908273471142.\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0205 - val_loss: 0.0456 - learning_rate: 9.9909e-04\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.0009990808456220278.\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0257 - val_loss: 0.0450 - learning_rate: 9.9908e-04\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 0.0009990708640963903.\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0254 - val_loss: 0.0461 - learning_rate: 9.9907e-04\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.000999060882770196.\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0225 - val_loss: 0.0461 - learning_rate: 9.9906e-04\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.0009990509016434388.\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0212 - val_loss: 0.0458 - learning_rate: 9.9905e-04\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.0009990409207161124.\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0185 - val_loss: 0.0441 - learning_rate: 9.9904e-04\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.0009990309399882115.\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0217 - val_loss: 0.0457 - learning_rate: 9.9903e-04\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.0009990209594597295.\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0244 - val_loss: 0.0459 - learning_rate: 9.9902e-04\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.0009990109791306607.\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0217 - val_loss: 0.0456 - learning_rate: 9.9901e-04\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(100, activation='relu',input_dim=X_train.shape[1]),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "lr_schedule = keras.callbacks.LearningRateScheduler(time_based_decay, verbose=1)\n",
    "\n",
    "history_t = model.fit(X_train,\n",
    "                                y_train, epochs=100, \n",
    "                                batch_size=300, \n",
    "                                validation_data=(X_val, y_val), \n",
    "                                callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exponential decay\n",
    "\n",
    "Repeat Part 3 Step 1 for a different learning schedule that uses exponential decay,\n",
    "\n",
    "$$ \\eta(t)=\\eta_0⋅e^{−k⋅t},$$\n",
    "\n",
    "where $k$ is the decay rate. We can try k=0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(epoch, lr):\n",
    "    initial_lr = 0.001\n",
    "    k = 0.01\n",
    "    new_lr = initial_lr * np.exp(-k * epoch)\n",
    "    return new_lr\n",
    "\n",
    "epochs=np.arange(100)\n",
    "lr=0.001\n",
    "learning_rates = [exponential_decay(epoch, lr) for epoch in epochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, learning_rates)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Exponential Decay Learning Rate Schedule')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.4306 - val_loss: 0.2464 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.000990049833749168.\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1914 - val_loss: 0.1202 - learning_rate: 9.9005e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0009801986733067552.\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0921 - val_loss: 0.0782 - learning_rate: 9.8020e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0009704455335485082.\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0697 - val_loss: 0.0607 - learning_rate: 9.7045e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0009607894391523232.\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0441 - val_loss: 0.0562 - learning_rate: 9.6079e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.000951229424500714.\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0391 - val_loss: 0.0563 - learning_rate: 9.5123e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0009417645335842487.\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0437 - val_loss: 0.0548 - learning_rate: 9.4176e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0009323938199059483.\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0426 - val_loss: 0.0543 - learning_rate: 9.3239e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0009231163463866358.\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0390 - val_loss: 0.0533 - learning_rate: 9.2312e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0009139311852712283.\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0490 - val_loss: 0.0530 - learning_rate: 9.1393e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0009048374180359595.\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0487 - val_loss: 0.0525 - learning_rate: 9.0484e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0008958341352965282.\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0391 - val_loss: 0.0513 - learning_rate: 8.9583e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0008869204367171575.\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0487 - val_loss: 0.0514 - learning_rate: 8.8692e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0008780954309205613.\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0325 - val_loss: 0.0508 - learning_rate: 8.7810e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0008693582353988059.\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0358 - val_loss: 0.0507 - learning_rate: 8.6936e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0008607079764250578.\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0379 - val_loss: 0.0507 - learning_rate: 8.6071e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0008521437889662113.\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0334 - val_loss: 0.0505 - learning_rate: 8.5214e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0008436648165963838.\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0465 - val_loss: 0.0511 - learning_rate: 8.4366e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.000835270211411272.\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0388 - val_loss: 0.0506 - learning_rate: 8.3527e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0008269591339433623.\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0399 - val_loss: 0.0496 - learning_rate: 8.2696e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0008187307530779819.\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0343 - val_loss: 0.0495 - learning_rate: 8.1873e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0008105842459701871.\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0346 - val_loss: 0.0501 - learning_rate: 8.1058e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0008025187979624785.\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0380 - val_loss: 0.0500 - learning_rate: 8.0252e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.000794533602503334.\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0490 - learning_rate: 7.9453e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0007866278610665535.\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0401 - val_loss: 0.0487 - learning_rate: 7.8663e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0007788007830714049.\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0328 - val_loss: 0.0487 - learning_rate: 7.7880e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0007710515858035663.\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0491 - learning_rate: 7.7105e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0007633794943368531.\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0288 - val_loss: 0.0493 - learning_rate: 7.6338e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0007557837414557255.\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0356 - val_loss: 0.0483 - learning_rate: 7.5578e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0007482635675785653.\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0320 - val_loss: 0.0481 - learning_rate: 7.4826e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0007408182206817179.\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0340 - val_loss: 0.0482 - learning_rate: 7.4082e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0007334469562242892.\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0479 - learning_rate: 7.3345e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.000726149037073691.\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0478 - learning_rate: 7.2615e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0007189237334319262.\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0363 - val_loss: 0.0472 - learning_rate: 7.1892e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0007117703227626096.\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.0472 - learning_rate: 7.1177e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0007046880897187134.\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0336 - val_loss: 0.0472 - learning_rate: 7.0469e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.000697676326071031.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0371 - val_loss: 0.0470 - learning_rate: 6.9768e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0006907343306373547.\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0319 - val_loss: 0.0470 - learning_rate: 6.9073e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0006838614092123559.\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0292 - val_loss: 0.0466 - learning_rate: 6.8386e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0006770568744981646.\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0319 - val_loss: 0.0476 - learning_rate: 6.7706e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0006703200460356394.\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0297 - val_loss: 0.0466 - learning_rate: 6.7032e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.0006636502501363194.\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0467 - learning_rate: 6.6365e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0006570468198150568.\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0293 - val_loss: 0.0463 - learning_rate: 6.5705e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0006505090947233165.\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0466 - learning_rate: 6.5051e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0006440364210831414.\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0471 - learning_rate: 6.4404e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0006376281516217733.\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0341 - val_loss: 0.0473 - learning_rate: 6.3763e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.000631283645506926.\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0287 - val_loss: 0.0497 - learning_rate: 6.3128e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0006250022682827008.\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0306 - val_loss: 0.0469 - learning_rate: 6.2500e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0006187833918061408.\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0304 - val_loss: 0.0472 - learning_rate: 6.1878e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.0006126263941844161.\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0295 - val_loss: 0.0464 - learning_rate: 6.1263e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.0006065306597126335.\n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0265 - val_loss: 0.0466 - learning_rate: 6.0653e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.000600495578812266.\n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.0471 - learning_rate: 6.0050e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0005945205479701944.\n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0462 - learning_rate: 5.9452e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.0005886049696783552.\n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0301 - val_loss: 0.0471 - learning_rate: 5.8860e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0005827482523739897.\n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0461 - learning_rate: 5.8275e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.0005769498103804867.\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0271 - val_loss: 0.0467 - learning_rate: 5.7695e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.0005712090638488148.\n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0275 - val_loss: 0.0474 - learning_rate: 5.7121e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0005655254386995371.\n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0266 - val_loss: 0.0460 - learning_rate: 5.6553e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.000559898366565402.\n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0298 - val_loss: 0.0456 - learning_rate: 5.5990e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.0005543272847345071.\n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0266 - val_loss: 0.0453 - learning_rate: 5.5433e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.0005488116360940265.\n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0274 - val_loss: 0.0457 - learning_rate: 5.4881e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.0005433508690744998.\n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0329 - val_loss: 0.0460 - learning_rate: 5.4335e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.0005379444375946745.\n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0264 - val_loss: 0.0458 - learning_rate: 5.3794e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.0005325918010068972.\n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0313 - val_loss: 0.0458 - learning_rate: 5.3259e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.0005272924240430486.\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0454 - learning_rate: 5.2729e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.000522045776761016.\n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0449 - learning_rate: 5.2205e-04\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.0005168513344916992.\n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0263 - val_loss: 0.0456 - learning_rate: 5.1685e-04\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.0005117085777865425.\n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0456 - learning_rate: 5.1171e-04\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.0005066169923655895.\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.0450 - learning_rate: 5.0662e-04\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.0005015760690660555.\n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0258 - val_loss: 0.0449 - learning_rate: 5.0158e-04\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.0004965853037914095.\n",
      "Epoch 71/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0297 - val_loss: 0.0454 - learning_rate: 4.9659e-04\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.0004916441974609651.\n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0215 - val_loss: 0.0449 - learning_rate: 4.9164e-04\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.0004867522559599717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0456 - learning_rate: 4.8675e-04\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.00048190899009020245.\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0252 - val_loss: 0.0450 - learning_rate: 4.8191e-04\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.0004771139155210344.\n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0250 - val_loss: 0.0446 - learning_rate: 4.7711e-04\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.0004723665527410147.\n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0253 - val_loss: 0.0447 - learning_rate: 4.7237e-04\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.00046766642700990925.\n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0290 - val_loss: 0.0447 - learning_rate: 4.6767e-04\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.00046301306831122806.\n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0445 - learning_rate: 4.6301e-04\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.00045840601130522354.\n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0454 - learning_rate: 4.5841e-04\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.0004538447952823558.\n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0323 - val_loss: 0.0447 - learning_rate: 4.5384e-04\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.0004493289641172216.\n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0284 - val_loss: 0.0447 - learning_rate: 4.4933e-04\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.0004448580662229411.\n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0440 - learning_rate: 4.4486e-04\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.0004404316545059993.\n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0440 - learning_rate: 4.4043e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.0004360492863215356.\n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0237 - val_loss: 0.0448 - learning_rate: 4.3605e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.00043171052342907973.\n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0447 - learning_rate: 4.3171e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.0004274149319487267.\n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0445 - learning_rate: 4.2741e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.00042316208231774885.\n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0236 - val_loss: 0.0443 - learning_rate: 4.2316e-04\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.000418951549247639.\n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0241 - val_loss: 0.0437 - learning_rate: 4.1895e-04\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.0004147829116815814.\n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0253 - val_loss: 0.0436 - learning_rate: 4.1478e-04\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.0004106557527523455.\n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0262 - val_loss: 0.0441 - learning_rate: 4.1066e-04\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.00040656965974059914.\n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0289 - val_loss: 0.0437 - learning_rate: 4.0657e-04\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.00040252422403363596.\n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0228 - val_loss: 0.0437 - learning_rate: 4.0252e-04\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.00039851904108451417.\n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0246 - val_loss: 0.0439 - learning_rate: 3.9852e-04\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 0.0003945537103716011.\n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0270 - val_loss: 0.0440 - learning_rate: 3.9455e-04\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.00039062783535852107.\n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0256 - val_loss: 0.0430 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.00038674102345450116.\n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0266 - val_loss: 0.0437 - learning_rate: 3.8674e-04\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.0003828928859751121.\n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0435 - learning_rate: 3.8289e-04\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.00037908303810339886.\n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0329 - val_loss: 0.0441 - learning_rate: 3.7908e-04\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.0003753110988513996.\n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0260 - val_loss: 0.0439 - learning_rate: 3.7531e-04\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.0003715766910220457.\n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0275 - val_loss: 0.0434 - learning_rate: 3.7158e-04\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    Dense(100, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "lr_schedule = keras.callbacks.LearningRateScheduler(exponential_decay, verbose=1)\n",
    "\n",
    "history_exp = model.fit(X_train,\n",
    "                                y_train, epochs=100, \n",
    "                                batch_size=300, \n",
    "                                validation_data=(X_val, y_val), \n",
    "                                callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: \n",
    "\n",
    "Graph the loss for the three learning schedules we have (constant, time decay, exponential decay). Zoom in on the values at the end of the training to better see the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2240b09b3a0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],label='Constant LR Training')\n",
    "plt.plot(history.history['val_loss'],label='Constant LR Validation')\n",
    "plt.plot(history_t.history['loss'], label='Time Decay LR Training')\n",
    "plt.plot(history_t.history['val_loss'], label='Time Decay LR Validation')\n",
    "plt.plot(history_exp.history['loss'], label='Exponential Decay LR Training')\n",
    "plt.plot(history_exp.history['val_loss'], label='Exponential Decay LR Validation')\n",
    "\n",
    "plt.xlim(90,100)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Comparison')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: A first convolutional neural network\n",
    "\n",
    "In the following, we try to improve on our dense NN for the MNIST image dataset with a deep convolutional network. There are two new kinds of layers that will be used, **Conv2D** and **MaxPool2D**. We will discuss this in detail next week, but for now just look at the code. While the code runs, try to figure out the structure of the network. You might want to look up these layers in the keras documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (50000, 28, 28, 1)\n",
      "y_train.shape = (50000,)\n",
      "x_val.shape = (10000, 28, 28, 1)\n",
      "y_val.shape = (10000,)\n",
      "x_test.shape = (10000, 28, 28, 1)\n",
      "y_test.shape = (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  \n",
    "\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "\tx_train, y_train, test_size = 1/6, random_state=42)\n",
    "\n",
    "print('x_train.shape =', x_train.shape)\n",
    "print('y_train.shape =', y_train.shape)\n",
    "print('x_val.shape =', x_val.shape)\n",
    "print('y_val.shape =', y_val.shape)\n",
    "print('x_test.shape =', x_test.shape)\n",
    "print('y_test.shape =', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "C:\\Users\\antho\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,510</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1960</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">125,504</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │           \u001b[38;5;34m260\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │         \u001b[38;5;34m2,510\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1960\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_97 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m125,504\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_98 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,924</span> (503.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m128,924\u001b[0m (503.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,924</span> (503.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m128,924\u001b[0m (503.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_34\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_34\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_99 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_101 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">535,818</span> (2.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m535,818\u001b[0m (2.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "def make_conv_model():\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Conv2D(filters = 10, kernel_size = (5,5),padding = 'Same', \n",
    "                  activation ='relu', input_shape = (28,28,1)))\n",
    "  model.add(Conv2D(filters = 10, kernel_size = (5,5),padding = 'Same', \n",
    "                  activation ='relu'))\n",
    "  model.add(MaxPool2D(pool_size=(2,2)))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(64, activation = \"relu\"))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(10, activation = \"softmax\"))\n",
    "  optimizer = keras.optimizers.Adam()\n",
    "\n",
    "  model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']) \n",
    "  return model\n",
    "\n",
    "def make_dense_model():\n",
    "  model = Sequential()\n",
    "  model.add(Flatten(input_shape = (28,28,1)))\n",
    "  model.add(Dense(512, activation = \"relu\"))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(256, activation = \"relu\"))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(10, activation = \"softmax\"))\n",
    "  optimizer = keras.optimizers.Adam()\n",
    "\n",
    "  model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']) \n",
    "  return model\n",
    "\n",
    "simple_conv_model = make_conv_model()\n",
    "dense_model = make_dense_model()\n",
    "simple_conv_model.summary()\n",
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8440 - loss: 0.5171 - val_accuracy: 0.9788 - val_loss: 0.0725\n",
      "Epoch 2/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 24ms/step - accuracy: 0.9721 - loss: 0.0922 - val_accuracy: 0.9820 - val_loss: 0.0542\n",
      "Epoch 3/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 24ms/step - accuracy: 0.9806 - loss: 0.0620 - val_accuracy: 0.9857 - val_loss: 0.0481\n",
      "Epoch 4/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - accuracy: 0.9852 - loss: 0.0478 - val_accuracy: 0.9883 - val_loss: 0.0403\n",
      "Epoch 5/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9864 - loss: 0.0425 - val_accuracy: 0.9888 - val_loss: 0.0383\n",
      "Epoch 6/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.9896 - loss: 0.0325 - val_accuracy: 0.9887 - val_loss: 0.0390\n",
      "Epoch 7/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - accuracy: 0.9907 - loss: 0.0302 - val_accuracy: 0.9876 - val_loss: 0.0447\n",
      "Epoch 8/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.9912 - loss: 0.0266 - val_accuracy: 0.9889 - val_loss: 0.0424\n",
      "Epoch 9/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9918 - loss: 0.0262 - val_accuracy: 0.9889 - val_loss: 0.0408\n",
      "Epoch 10/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9930 - loss: 0.0203 - val_accuracy: 0.9863 - val_loss: 0.0489\n",
      "Epoch 11/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9928 - loss: 0.0193 - val_accuracy: 0.9895 - val_loss: 0.0417\n",
      "Epoch 12/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9927 - loss: 0.0193 - val_accuracy: 0.9896 - val_loss: 0.0429\n",
      "Epoch 13/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 32ms/step - accuracy: 0.9957 - loss: 0.0130 - val_accuracy: 0.9901 - val_loss: 0.0447\n",
      "Epoch 14/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0144 - val_accuracy: 0.9903 - val_loss: 0.0436\n",
      "Epoch 15/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9956 - loss: 0.0140 - val_accuracy: 0.9891 - val_loss: 0.0466\n",
      "Epoch 16/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9956 - loss: 0.0124 - val_accuracy: 0.9905 - val_loss: 0.0456\n",
      "Epoch 17/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9961 - loss: 0.0127 - val_accuracy: 0.9901 - val_loss: 0.0436\n",
      "Epoch 18/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0125 - val_accuracy: 0.9898 - val_loss: 0.0474\n",
      "Epoch 19/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9967 - loss: 0.0106 - val_accuracy: 0.9906 - val_loss: 0.0474\n",
      "Epoch 20/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9961 - loss: 0.0114 - val_accuracy: 0.9897 - val_loss: 0.0498\n",
      "Epoch 21/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9970 - loss: 0.0102 - val_accuracy: 0.9888 - val_loss: 0.0523\n",
      "Epoch 22/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9969 - loss: 0.0086 - val_accuracy: 0.9898 - val_loss: 0.0554\n",
      "Epoch 23/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9965 - loss: 0.0099 - val_accuracy: 0.9893 - val_loss: 0.0543\n",
      "Epoch 24/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0082 - val_accuracy: 0.9898 - val_loss: 0.0601\n",
      "Epoch 25/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0080 - val_accuracy: 0.9905 - val_loss: 0.0550\n",
      "Epoch 26/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9971 - loss: 0.0082 - val_accuracy: 0.9906 - val_loss: 0.0546\n",
      "Epoch 27/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0073 - val_accuracy: 0.9912 - val_loss: 0.0567\n",
      "Epoch 28/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 0.9897 - val_loss: 0.0613\n",
      "Epoch 29/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9978 - loss: 0.0062 - val_accuracy: 0.9906 - val_loss: 0.0584\n",
      "Epoch 30/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9975 - loss: 0.0073 - val_accuracy: 0.9910 - val_loss: 0.0619\n",
      "Epoch 31/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0068 - val_accuracy: 0.9898 - val_loss: 0.0652\n",
      "Epoch 32/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - accuracy: 0.9972 - loss: 0.0077 - val_accuracy: 0.9902 - val_loss: 0.0657\n",
      "Epoch 33/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9979 - loss: 0.0058 - val_accuracy: 0.9908 - val_loss: 0.0632\n",
      "Epoch 34/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0060 - val_accuracy: 0.9900 - val_loss: 0.0678\n",
      "Epoch 35/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9979 - loss: 0.0057 - val_accuracy: 0.9910 - val_loss: 0.0596\n",
      "Epoch 36/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9980 - loss: 0.0059 - val_accuracy: 0.9898 - val_loss: 0.0743\n",
      "Epoch 37/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 0.9906 - val_loss: 0.0569\n",
      "Epoch 38/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9978 - loss: 0.0054 - val_accuracy: 0.9908 - val_loss: 0.0651\n",
      "Epoch 39/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9975 - loss: 0.0075 - val_accuracy: 0.9904 - val_loss: 0.0726\n",
      "Epoch 40/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9976 - loss: 0.0065 - val_accuracy: 0.9905 - val_loss: 0.0624\n",
      "Epoch 1/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8540 - loss: 0.4810 - val_accuracy: 0.9637 - val_loss: 0.1138\n",
      "Epoch 2/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9646 - loss: 0.1180 - val_accuracy: 0.9690 - val_loss: 0.0946\n",
      "Epoch 3/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9751 - loss: 0.0814 - val_accuracy: 0.9749 - val_loss: 0.0786\n",
      "Epoch 4/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9807 - loss: 0.0611 - val_accuracy: 0.9796 - val_loss: 0.0698\n",
      "Epoch 5/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.0489 - val_accuracy: 0.9801 - val_loss: 0.0644\n",
      "Epoch 6/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9866 - loss: 0.0411 - val_accuracy: 0.9816 - val_loss: 0.0673\n",
      "Epoch 7/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9879 - loss: 0.0390 - val_accuracy: 0.9780 - val_loss: 0.0794\n",
      "Epoch 8/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9878 - loss: 0.0357 - val_accuracy: 0.9818 - val_loss: 0.0649\n",
      "Epoch 9/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0256 - val_accuracy: 0.9821 - val_loss: 0.0741\n",
      "Epoch 10/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9907 - loss: 0.0276 - val_accuracy: 0.9816 - val_loss: 0.0691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.0250 - val_accuracy: 0.9822 - val_loss: 0.0708\n",
      "Epoch 12/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.0242 - val_accuracy: 0.9814 - val_loss: 0.0789\n",
      "Epoch 13/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.0222 - val_accuracy: 0.9843 - val_loss: 0.0677\n",
      "Epoch 14/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0217 - val_accuracy: 0.9837 - val_loss: 0.0724\n",
      "Epoch 15/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9929 - loss: 0.0198 - val_accuracy: 0.9815 - val_loss: 0.0923\n",
      "Epoch 16/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9932 - loss: 0.0208 - val_accuracy: 0.9819 - val_loss: 0.0851\n",
      "Epoch 17/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0154 - val_accuracy: 0.9831 - val_loss: 0.0893\n",
      "Epoch 18/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9940 - loss: 0.0171 - val_accuracy: 0.9831 - val_loss: 0.0824\n",
      "Epoch 19/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0171 - val_accuracy: 0.9827 - val_loss: 0.0820\n",
      "Epoch 20/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0148 - val_accuracy: 0.9826 - val_loss: 0.0881\n",
      "Epoch 21/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9950 - loss: 0.0155 - val_accuracy: 0.9844 - val_loss: 0.0797\n",
      "Epoch 22/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9960 - loss: 0.0126 - val_accuracy: 0.9847 - val_loss: 0.0823\n",
      "Epoch 23/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9952 - loss: 0.0151 - val_accuracy: 0.9837 - val_loss: 0.0865\n",
      "Epoch 24/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0163 - val_accuracy: 0.9830 - val_loss: 0.0873\n",
      "Epoch 25/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9959 - loss: 0.0132 - val_accuracy: 0.9834 - val_loss: 0.0996\n",
      "Epoch 26/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9947 - loss: 0.0194 - val_accuracy: 0.9841 - val_loss: 0.0873\n",
      "Epoch 27/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9972 - loss: 0.0091 - val_accuracy: 0.9815 - val_loss: 0.1027\n",
      "Epoch 28/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0154 - val_accuracy: 0.9834 - val_loss: 0.0932\n",
      "Epoch 29/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9962 - loss: 0.0118 - val_accuracy: 0.9840 - val_loss: 0.0824\n",
      "Epoch 30/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.0163 - val_accuracy: 0.9845 - val_loss: 0.0897\n",
      "Epoch 31/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0108 - val_accuracy: 0.9817 - val_loss: 0.1009\n",
      "Epoch 32/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9960 - loss: 0.0129 - val_accuracy: 0.9837 - val_loss: 0.0928\n",
      "Epoch 33/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9964 - loss: 0.0112 - val_accuracy: 0.9859 - val_loss: 0.0927\n",
      "Epoch 34/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 0.9825 - val_loss: 0.1073\n",
      "Epoch 35/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9965 - loss: 0.0116 - val_accuracy: 0.9838 - val_loss: 0.0956\n",
      "Epoch 36/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9959 - loss: 0.0152 - val_accuracy: 0.9845 - val_loss: 0.0959\n",
      "Epoch 37/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0110 - val_accuracy: 0.9826 - val_loss: 0.1118\n",
      "Epoch 38/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9959 - loss: 0.0158 - val_accuracy: 0.9847 - val_loss: 0.0949\n",
      "Epoch 39/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9971 - loss: 0.0091 - val_accuracy: 0.9853 - val_loss: 0.0915\n",
      "Epoch 40/40\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0089 - val_accuracy: 0.9856 - val_loss: 0.0920\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "batch_size = 86\n",
    "\n",
    "simple_conv_history = simple_conv_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val), verbose=1)\n",
    "dense_history = dense_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9869 - loss: 0.0672\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.1161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22409aedc40>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_conv_test_loss, simple_conv_test_acc = simple_conv_model.evaluate(x_test, y_test)\n",
    "dense_test_loss, dense_test_acc = dense_model.evaluate(x_test, y_test)\n",
    "\n",
    "plt.plot(dense_history.history[\"accuracy\"], \"b--\",label=\"dense training accuracy\")\n",
    "plt.plot(dense_history.history[\"val_accuracy\"], \"b-\",label=\"dense val accuracy\")\n",
    "plt.axhline(dense_test_acc, color=\"k\", linestyle=\":\", label=\"dense test accuracy\")\n",
    "plt.plot(simple_conv_history.history[\"accuracy\"], \"g--\",label=\"simple conv training accuracy\")\n",
    "plt.plot(simple_conv_history.history[\"val_accuracy\"], \"g-\",label=\"simple conv val accuracy\")\n",
    "plt.axhline(simple_conv_test_acc,color=\"k\", linestyle=\"--\", label=\"simple conv test accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0.94, 1.005)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
